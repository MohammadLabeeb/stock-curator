{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production ML Prediction for LLM Stock Recommendations\n",
    "\n",
    "## Purpose\n",
    "Get ML predictions for ALL LLM-extracted stock recommendations using the trained XGBoost model (70.08% accuracy).\n",
    "\n",
    "## Workflow\n",
    "1. **Input**: List of stock symbols from LLM (e.g., `['RELIANCE', 'TCS', 'INFY']`)\n",
    "2. **Fetch**: Get 60-day historical data for each stock\n",
    "3. **Engineer**: Calculate all 47 technical features\n",
    "4. **Predict**: Use trained XGBoost model to predict 7-day direction\n",
    "5. **Display**: Show predictions for ALL stocks (UP/DOWN with confidence)\n",
    "\n",
    "## Model Performance\n",
    "- **Accuracy**: 70.08%\n",
    "- **Precision**: 73.10% (when it says UP, it's right 73% of the time)\n",
    "- **Win Rate**: 70.81% in trading simulation\n",
    "- **Sharpe Ratio**: 0.4992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# API requests\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded\n",
      "Model path: models/xgboost_stock_direction_predictor.pkl\n",
      "Scaler path: models/feature_scaler.pkl\n",
      "Features: 47 features\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "WINDOW_SIZE = 60          # Need 60 days of history\n",
    "HORIZON = 7               # Predicting 7-day ahead direction\n",
    "\n",
    "# Paths\n",
    "MODELS_DIR = Path(\"models\")\n",
    "MODEL_PATH = MODELS_DIR / \"xgboost_stock_direction_predictor.pkl\"\n",
    "SCALER_PATH = MODELS_DIR / \"feature_scaler.pkl\"\n",
    "\n",
    "# Upstox API\n",
    "UPSTOX_ACCESS_TOKEN = os.getenv(\"UPSTOX_ACCESS_TOKEN\")\n",
    "\n",
    "# Feature list (47 features in the exact order used during training)\n",
    "FEATURE_COLS = [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume', 'OI',\n",
    "    'SMA_5', 'SMA_10', 'SMA_20', 'SMA_50',\n",
    "    'EMA_12', 'EMA_26', 'MACD', 'MACD_Signal', 'MACD_Hist',\n",
    "    'RSI', 'BB_Middle', 'BB_Upper', 'BB_Lower',\n",
    "    'Volume_SMA_20', 'Volume_Ratio', 'Daily_Return', 'Price_Range', 'Price_Change',\n",
    "    'Return_3d', 'Return_5d', 'Return_10d', 'Log_Return',\n",
    "    'Volatility_5d', 'Volatility_20d', 'Momentum_10d', 'Momentum_20d',\n",
    "    # Advanced features (15)\n",
    "    'relative_strength_to_nifty50', 'correlation_to_nifty50_20d', 'market_regime',\n",
    "    'rsi_divergence', 'macd_crossover_signal', 'bb_squeeze',\n",
    "    'price_vs_sma50_pct', 'momentum_strength', 'support_resistance_distance',\n",
    "    'volume_price_trend', 'on_balance_volume', 'volume_breakout',\n",
    "    'returns_skewness_20d', 'returns_kurtosis_20d', 'hurst_exponent'\n",
    "]\n",
    "\n",
    "print(f\"Configuration loaded\")\n",
    "print(f\"Model path: {MODEL_PATH}\")\n",
    "print(f\"Scaler path: {SCALER_PATH}\")\n",
    "print(f\"Features: {len(FEATURE_COLS)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stock lookup data loaded (2252 stocks)\n",
      "‚úÖ Stock lookup functions defined\n"
     ]
    }
   ],
   "source": [
    "# Load stock lookup data for symbol to ISIN conversion\n",
    "import json\n",
    "\n",
    "STOCK_LOOKUP_PATH = Path(\"data/processed/stock_lookup.json\")\n",
    "\n",
    "if STOCK_LOOKUP_PATH.exists():\n",
    "    with open(STOCK_LOOKUP_PATH, 'r') as f:\n",
    "        stock_lookup = json.load(f)\n",
    "    print(f\"‚úÖ Stock lookup data loaded ({len(stock_lookup['by_symbol'])} stocks)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Warning: stock_lookup.json not found. API calls will fail.\")\n",
    "    stock_lookup = {'by_symbol': {}}\n",
    "\n",
    "def get_isin_for_symbol(symbol):\n",
    "    \"\"\"Convert stock symbol to ISIN code\"\"\"\n",
    "    if symbol in stock_lookup['by_symbol']:\n",
    "        return stock_lookup['by_symbol'][symbol]['isin']\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  ISIN not found for {symbol}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Stock lookup functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Trained Model and Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model and scaler loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Note: Run notebook 09 first to train and save the model\n",
    "# For now, we'll handle the case where model doesn't exist yet\n",
    "\n",
    "if MODEL_PATH.exists() and SCALER_PATH.exists():\n",
    "    with open(MODEL_PATH, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    with open(SCALER_PATH, 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    print(\"‚úÖ Model and scaler loaded successfully\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Model files not found!\")\n",
    "    print(\"   Please run notebook 09 first to train and save the model.\")\n",
    "    model = None\n",
    "    scaler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Fetching Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ HTTP session created\n"
     ]
    }
   ],
   "source": [
    "def create_session_with_retries(retries=3, backoff_factor=0.3):\n",
    "    \"\"\"Create a requests session with retry logic\"\"\"\n",
    "    session = requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=(500, 502, 504),\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "session = create_session_with_retries()\n",
    "print(\"‚úÖ HTTP session created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ fetch_stock_data() defined (using ISIN)\n"
     ]
    }
   ],
   "source": [
    "def fetch_stock_data(symbol, days=200, access_token=None):\n",
    "    \"\"\"\n",
    "    Fetch historical stock data from Upstox API using ISIN\n",
    "    \n",
    "    Args:\n",
    "        symbol: Stock symbol (e.g., 'RELIANCE')\n",
    "        days: Number of days to fetch (default 200 to ensure 60+ after feature engineering)\n",
    "        access_token: Upstox API token\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with OHLCV data, or None if failed\n",
    "    \"\"\"\n",
    "    if access_token is None:\n",
    "        access_token = UPSTOX_ACCESS_TOKEN\n",
    "    \n",
    "    if not access_token:\n",
    "        print(f\"‚ö†Ô∏è  Error: UPSTOX_ACCESS_TOKEN not set\")\n",
    "        return None\n",
    "    \n",
    "    # ‚úÖ FIX: Convert symbol to ISIN\n",
    "    isin = get_isin_for_symbol(symbol)\n",
    "    if isin is None:\n",
    "        return None\n",
    "    \n",
    "    # Calculate date range\n",
    "    end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    start_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # ‚úÖ FIX: Build URL using ISIN (same as notebook 02)\n",
    "    instrument_key = f\"NSE_EQ%7C{isin}\"  # Use ISIN, not symbol\n",
    "    url = f\"https://api.upstox.com/v3/historical-candle/{instrument_key}/days/1/{end_date}/{start_date}\"\n",
    "    \n",
    "    headers = {\n",
    "        'Accept': 'application/json',\n",
    "        'Authorization': f'Bearer {access_token}'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = session.get(url, headers=headers, timeout=15)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            if data.get('status') == 'success' and 'data' in data:\n",
    "                candles = data['data'].get('candles', [])\n",
    "                \n",
    "                if not candles:\n",
    "                    print(f\"‚ö†Ô∏è  No data for {symbol}\")\n",
    "                    return None\n",
    "                \n",
    "                # Convert to DataFrame\n",
    "                df = pd.DataFrame(candles, columns=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'OI'])\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "                df = df.sort_values('Date').reset_index(drop=True)\n",
    "                df['Symbol'] = symbol\n",
    "                \n",
    "                return df\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  API error for {symbol}: {data.get('message', 'Unknown')}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  HTTP {response.status_code} for {symbol}\")\n",
    "            return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Exception fetching {symbol}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ fetch_stock_data() defined (using ISIN)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ fetch_nifty50_data() defined\n"
     ]
    }
   ],
   "source": [
    "def fetch_nifty50_data(days=200, access_token=None):\n",
    "    \"\"\"\n",
    "    Fetch NIFTY 50 index data\n",
    "    \"\"\"\n",
    "    if access_token is None:\n",
    "        access_token = UPSTOX_ACCESS_TOKEN\n",
    "    \n",
    "    if not access_token:\n",
    "        print(\"‚ö†Ô∏è  Error: UPSTOX_ACCESS_TOKEN not set\")\n",
    "        return None\n",
    "    \n",
    "    end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    start_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    instrument_key_encoded = \"NSE_INDEX%7CNifty%2050\"\n",
    "    url = f\"https://api.upstox.com/v3/historical-candle/{instrument_key_encoded}/days/1/{end_date}/{start_date}\"\n",
    "    \n",
    "    headers = {\n",
    "        'Accept': 'application/json',\n",
    "        'Authorization': f'Bearer {access_token}'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = session.get(url, headers=headers, timeout=15)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            if data.get('status') == 'success' and 'data' in data:\n",
    "                candles = data['data'].get('candles', [])\n",
    "                \n",
    "                if not candles:\n",
    "                    return None\n",
    "                \n",
    "                df = pd.DataFrame(candles, columns=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'OI'])\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "                df = df.sort_values('Date').reset_index(drop=True)\n",
    "                df = df[['Date', 'Close']]\n",
    "                df.rename(columns={'Close': 'Nifty50_Close'}, inplace=True)\n",
    "                \n",
    "                return df\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Exception fetching NIFTY 50: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ fetch_nifty50_data() defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Feature Engineering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ calculate_basic_features() defined\n"
     ]
    }
   ],
   "source": [
    "def calculate_basic_features(df):\n",
    "    \"\"\"\n",
    "    Calculate basic technical indicators (first 32 features)\n",
    "    Assumes df has OHLCV columns\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Simple Moving Averages\n",
    "    df['SMA_5'] = df['Close'].rolling(5).mean()\n",
    "    df['SMA_10'] = df['Close'].rolling(10).mean()\n",
    "    df['SMA_20'] = df['Close'].rolling(20).mean()\n",
    "    df['SMA_50'] = df['Close'].rolling(50).mean()\n",
    "    \n",
    "    # Exponential Moving Averages\n",
    "    df['EMA_12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    df['EMA_26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    \n",
    "    # MACD\n",
    "    df['MACD'] = df['EMA_12'] - df['EMA_26']\n",
    "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    df['MACD_Hist'] = df['MACD'] - df['MACD_Signal']\n",
    "    \n",
    "    # RSI\n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
    "    loss = -delta.where(delta < 0, 0).rolling(14).mean()\n",
    "    rs = gain / (loss + 1e-8)\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    df['BB_Middle'] = df['Close'].rolling(20).mean()\n",
    "    bb_std = df['Close'].rolling(20).std()\n",
    "    df['BB_Upper'] = df['BB_Middle'] + (2 * bb_std)\n",
    "    df['BB_Lower'] = df['BB_Middle'] - (2 * bb_std)\n",
    "    \n",
    "    # Volume indicators\n",
    "    df['Volume_SMA_20'] = df['Volume'].rolling(20).mean()\n",
    "    df['Volume_Ratio'] = df['Volume'] / (df['Volume_SMA_20'] + 1e-8)\n",
    "    \n",
    "    # Price-based features\n",
    "    df['Daily_Return'] = df['Close'].pct_change() * 100\n",
    "    df['Price_Range'] = df['High'] - df['Low']\n",
    "    df['Price_Change'] = df['Close'] - df['Open']\n",
    "    \n",
    "    # Historical returns\n",
    "    df['Return_3d'] = df['Close'].pct_change(3) * 100\n",
    "    df['Return_5d'] = df['Close'].pct_change(5) * 100\n",
    "    df['Return_10d'] = df['Close'].pct_change(10) * 100\n",
    "    df['Log_Return'] = np.log(df['Close'] / df['Close'].shift(1)) * 100\n",
    "    \n",
    "    # Volatility\n",
    "    df['Volatility_5d'] = df['Daily_Return'].rolling(5).std()\n",
    "    df['Volatility_20d'] = df['Daily_Return'].rolling(20).std()\n",
    "    \n",
    "    # Momentum\n",
    "    df['Momentum_10d'] = df['Close'] - df['Close'].shift(10)\n",
    "    df['Momentum_20d'] = df['Close'] - df['Close'].shift(20)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ calculate_basic_features() defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ calculate_advanced_features() defined\n"
     ]
    }
   ],
   "source": [
    "def calculate_advanced_features(df, nifty50_df=None):\n",
    "    \"\"\"\n",
    "    Calculate advanced technical features (15 features)\n",
    "    This is the same function from notebook 09\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # ========== MARKET CONTEXT FEATURES (3) ==========\n",
    "    if nifty50_df is not None:\n",
    "        df = df.merge(nifty50_df, on='Date', how='left')\n",
    "        df['Nifty50_Return'] = df['Nifty50_Close'].pct_change() * 100\n",
    "        df['relative_strength_to_nifty50'] = df['Daily_Return'] - df['Nifty50_Return']\n",
    "        df['correlation_to_nifty50_20d'] = df['Daily_Return'].rolling(20).corr(df['Nifty50_Return'])\n",
    "        \n",
    "        nifty_sma_20 = df['Nifty50_Close'].rolling(20).mean()\n",
    "        nifty_sma_50 = df['Nifty50_Close'].rolling(50).mean()\n",
    "        df['market_regime'] = 0\n",
    "        df.loc[nifty_sma_20 > nifty_sma_50, 'market_regime'] = 1\n",
    "        df.loc[nifty_sma_20 < nifty_sma_50, 'market_regime'] = -1\n",
    "        \n",
    "        df.drop(columns=['Nifty50_Close', 'Nifty50_Return'], inplace=True)\n",
    "    else:\n",
    "        df['relative_strength_to_nifty50'] = np.nan\n",
    "        df['correlation_to_nifty50_20d'] = np.nan\n",
    "        df['market_regime'] = 0\n",
    "    \n",
    "    # ========== MOMENTUM & MEAN REVERSION (6) ==========\n",
    "    rsi_change = df['RSI'].diff(5)\n",
    "    price_change = df['Close'].pct_change(5)\n",
    "    df['rsi_divergence'] = np.sign(rsi_change) - np.sign(price_change)\n",
    "    \n",
    "    df['macd_crossover_signal'] = 0\n",
    "    macd_cross_up = (df['MACD'] > df['MACD_Signal']) & (df['MACD'].shift(1) <= df['MACD_Signal'].shift(1))\n",
    "    macd_cross_down = (df['MACD'] < df['MACD_Signal']) & (df['MACD'].shift(1) >= df['MACD_Signal'].shift(1))\n",
    "    df.loc[macd_cross_up, 'macd_crossover_signal'] = 1\n",
    "    df.loc[macd_cross_down, 'macd_crossover_signal'] = -1\n",
    "    \n",
    "    bb_width = (df['BB_Upper'] - df['BB_Lower']) / df['BB_Middle']\n",
    "    df['bb_squeeze'] = bb_width.rolling(20).apply(lambda x: (x.iloc[-1] - x.min()) / (x.max() - x.min() + 1e-8), raw=False)\n",
    "    \n",
    "    df['price_vs_sma50_pct'] = ((df['Close'] - df['SMA_50']) / df['SMA_50']) * 100\n",
    "    df['momentum_strength'] = df['Momentum_10d'].diff(5)\n",
    "    \n",
    "    high_20 = df['High'].rolling(20).max()\n",
    "    low_20 = df['Low'].rolling(20).min()\n",
    "    df['support_resistance_distance'] = np.where(\n",
    "        df['Close'] > df['Close'].shift(1),\n",
    "        (high_20 - df['Close']) / df['Close'],\n",
    "        (df['Close'] - low_20) / df['Close']\n",
    "    )\n",
    "    \n",
    "    # ========== VOLUME & LIQUIDITY (3) ==========\n",
    "    price_direction = np.sign(df['Close'].diff())\n",
    "    df['volume_price_trend'] = (df['Volume'] * price_direction).cumsum()\n",
    "    \n",
    "    obv = np.where(df['Close'] > df['Close'].shift(1), df['Volume'],\n",
    "                   np.where(df['Close'] < df['Close'].shift(1), -df['Volume'], 0))\n",
    "    df['on_balance_volume'] = obv.cumsum()\n",
    "    \n",
    "    df['volume_breakout'] = (df['Volume'] > 2 * df['Volume_SMA_20']).astype(int)\n",
    "    \n",
    "    # ========== STATISTICAL (3) ==========\n",
    "    df['returns_skewness_20d'] = df['Daily_Return'].rolling(20).skew()\n",
    "    df['returns_kurtosis_20d'] = df['Daily_Return'].rolling(20).kurt()\n",
    "    \n",
    "    def calculate_hurst(ts, lags=range(2, 20)):\n",
    "        if len(ts) < max(lags):\n",
    "            return 0.5\n",
    "        tau = []\n",
    "        lagvec = []\n",
    "        for lag in lags:\n",
    "            pp = np.subtract(ts[lag:], ts[:-lag])\n",
    "            lagvec.append(lag)\n",
    "            tau.append(np.std(pp))\n",
    "        try:\n",
    "            poly = np.polyfit(np.log(lagvec), np.log(tau), 1)\n",
    "            return poly[0]\n",
    "        except:\n",
    "            return 0.5\n",
    "    \n",
    "    df['hurst_exponent'] = df['Close'].rolling(60).apply(lambda x: calculate_hurst(x.values), raw=False)\n",
    "    \n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ calculate_advanced_features() defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ prepare_stock_for_prediction() defined\n"
     ]
    }
   ],
   "source": [
    "def prepare_stock_for_prediction(symbol, nifty50_df=None):\n",
    "    \"\"\"\n",
    "    Full pipeline: Fetch data ‚Üí Calculate features ‚Üí Prepare for model\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (features_array, latest_close_price, symbol) or (None, None, symbol) if failed\n",
    "    \"\"\"\n",
    "    # 1. Fetch stock data\n",
    "    df = fetch_stock_data(symbol, days=250)  # Extra buffer for feature calculation\n",
    "    \n",
    "    if df is None or len(df) < 70:\n",
    "        print(f\"   ‚ö†Ô∏è  {symbol}: Insufficient data\")\n",
    "        return None, None, symbol\n",
    "    \n",
    "    # 2. Calculate basic features\n",
    "    df = calculate_basic_features(df)\n",
    "    \n",
    "    # 3. Calculate advanced features\n",
    "    df = calculate_advanced_features(df, nifty50_df)\n",
    "    \n",
    "    if len(df) < WINDOW_SIZE:\n",
    "        print(f\"   ‚ö†Ô∏è  {symbol}: Not enough rows after feature engineering\")\n",
    "        return None, None, symbol\n",
    "    \n",
    "    # 4. Extract last 60 days of features\n",
    "    features_df = df[FEATURE_COLS].tail(WINDOW_SIZE)\n",
    "    \n",
    "    if features_df.isnull().any().any():\n",
    "        print(f\"   ‚ö†Ô∏è  {symbol}: NaN values in features\")\n",
    "        return None, None, symbol\n",
    "    \n",
    "    # 5. Convert to array (shape: 60, 47)\n",
    "    features_array = features_df.values\n",
    "    latest_close = df['Close'].iloc[-1]\n",
    "    \n",
    "    return features_array, latest_close, symbol\n",
    "\n",
    "print(\"‚úÖ prepare_stock_for_prediction() defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ predict_stock_direction() defined\n"
     ]
    }
   ],
   "source": [
    "def predict_stock_direction(features_array, model, scaler):\n",
    "    \"\"\"\n",
    "    Predict 7-day direction for a single stock\n",
    "    \n",
    "    Args:\n",
    "        features_array: numpy array of shape (60, 47)\n",
    "        model: Trained XGBoost model\n",
    "        scaler: Fitted StandardScaler\n",
    "    \n",
    "    Returns:\n",
    "        dict with prediction, probability, and confidence\n",
    "    \"\"\"\n",
    "    # 1. Reshape to (1, 60, 47) for single sample\n",
    "    X = features_array.reshape(1, WINDOW_SIZE, -1)\n",
    "    \n",
    "    # 2. Scale features (reshape to 2D first to match scaler training)\n",
    "    # Scaler was trained on (samples*60, 47), so we need to scale 47 features\n",
    "    X_2d = X.reshape(-1, 47)  # Shape: (60, 47)\n",
    "    X_scaled_2d = scaler.transform(X_2d)  # Scale each of the 47 features\n",
    "    \n",
    "    # 3. Reshape back to 3D then flatten for XGBoost\n",
    "    X_scaled = X_scaled_2d.reshape(1, WINDOW_SIZE, -1)  # (1, 60, 47)\n",
    "    X_flat = X_scaled.reshape(1, -1)  # (1, 2820)\n",
    "    \n",
    "    # 4. Predict\n",
    "    prediction = model.predict(X_flat)[0]  # 0 or 1\n",
    "    probabilities = model.predict_proba(X_flat)[0]  # [prob_down, prob_up]\n",
    "    \n",
    "    return {\n",
    "        'prediction': int(prediction),\n",
    "        'direction': 'UP' if prediction == 1 else 'DOWN',\n",
    "        'probability_up': probabilities[1],\n",
    "        'probability_down': probabilities[0],\n",
    "        'confidence': max(probabilities)\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ predict_stock_direction() defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Main Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ predict_llm_recommendations() defined\n"
     ]
    }
   ],
   "source": [
    "def predict_llm_recommendations(stock_symbols, model, scaler):\n",
    "    \"\"\"\n",
    "    Get ML predictions for ALL LLM stock recommendations\n",
    "    \n",
    "    Args:\n",
    "        stock_symbols: List of stock symbols (e.g., ['RELIANCE', 'TCS', 'INFY'])\n",
    "        model: Trained XGBoost model\n",
    "        scaler: Fitted StandardScaler\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with predictions for all stocks\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ML PREDICTIONS FOR {len(stock_symbols)} LLM-RECOMMENDED STOCKS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Fetch NIFTY 50 data once (for market context features)\n",
    "    print(\"Fetching NIFTY 50 data...\")\n",
    "    nifty50_df = fetch_nifty50_data(days=250)\n",
    "    \n",
    "    if nifty50_df is not None:\n",
    "        print(f\"‚úÖ NIFTY 50 data fetched ({len(nifty50_df)} days)\\n\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  NIFTY 50 data not available, using defaults\\n\")\n",
    "    \n",
    "    # Process each stock\n",
    "    results = []\n",
    "    \n",
    "    for i, symbol in enumerate(stock_symbols, 1):\n",
    "        print(f\"[{i}/{len(stock_symbols)}] Processing {symbol}...\")\n",
    "        \n",
    "        # Prepare features\n",
    "        features, latest_close, _ = prepare_stock_for_prediction(symbol, nifty50_df)\n",
    "        \n",
    "        if features is None:\n",
    "            results.append({\n",
    "                'symbol': symbol,\n",
    "                'status': 'FAILED',\n",
    "                'direction': 'N/A',\n",
    "                'confidence': None,\n",
    "                'probability_up': None,\n",
    "                'probability_down': None,\n",
    "                'latest_close': None,\n",
    "                'error': 'Insufficient data or feature engineering failed'\n",
    "            })\n",
    "            print(f\"   ‚ùå {symbol}: FAILED (insufficient data)\\n\")\n",
    "            continue\n",
    "        \n",
    "        # Predict\n",
    "        pred = predict_stock_direction(features, model, scaler)\n",
    "        \n",
    "        results.append({\n",
    "            'symbol': symbol,\n",
    "            'status': 'SUCCESS',\n",
    "            'direction': pred['direction'],\n",
    "            'confidence': pred['confidence'],\n",
    "            'probability_up': pred['probability_up'],\n",
    "            'probability_down': pred['probability_down'],\n",
    "            'latest_close': latest_close,\n",
    "            'error': None\n",
    "        })\n",
    "        \n",
    "        # Display direction with appropriate emoji\n",
    "        direction_emoji = 'üìà' if pred['direction'] == 'UP' else 'üìâ'\n",
    "        print(f\"   {direction_emoji} {symbol}: {pred['direction']} (confidence: {pred['confidence']:.1%})\")\n",
    "        print(f\"      Prob UP: {pred['probability_up']:.1%} | Prob DOWN: {pred['probability_down']:.1%}\")\n",
    "        print(f\"      Latest Price: ‚Çπ{latest_close:,.2f}\\n\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"PREDICTION SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total stocks:            {len(stock_symbols)}\")\n",
    "    print(f\"Successful predictions:  {len(results_df[results_df['status'] == 'SUCCESS'])}\")\n",
    "    print(f\"Failed predictions:      {len(results_df[results_df['status'] == 'FAILED'])}\")\n",
    "    \n",
    "    if len(results_df[results_df['status'] == 'SUCCESS']) > 0:\n",
    "        print(f\"\\nDirection Breakdown:\")\n",
    "        print(f\"  üìà Predicted UP:         {len(results_df[results_df['direction'] == 'UP'])}\")\n",
    "        print(f\"  üìâ Predicted DOWN:       {len(results_df[results_df['direction'] == 'DOWN'])}\")\n",
    "        \n",
    "        # Calculate average confidence\n",
    "        avg_conf = results_df[results_df['status'] == 'SUCCESS']['confidence'].mean()\n",
    "        print(f\"\\nAverage Confidence:      {avg_conf:.1%}\")\n",
    "    \n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "print(\"‚úÖ predict_llm_recommendations() defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Recommendations: ['RELIANCE', 'TCS', 'INFY', 'HDFCBANK', 'ICICIBANK']\n"
     ]
    }
   ],
   "source": [
    "# Example: LLM extracted these stocks from news\n",
    "llm_recommendations = [\n",
    "    'RELIANCE',\n",
    "    'TCS',\n",
    "    'INFY',\n",
    "    'HDFCBANK',\n",
    "    'ICICIBANK'\n",
    "]\n",
    "\n",
    "print(f\"LLM Recommendations: {llm_recommendations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ML PREDICTIONS FOR 5 LLM-RECOMMENDED STOCKS\n",
      "================================================================================\n",
      "\n",
      "Fetching NIFTY 50 data...\n",
      "‚úÖ NIFTY 50 data fetched (171 days)\n",
      "\n",
      "[1/5] Processing RELIANCE...\n",
      "   üìâ RELIANCE: DOWN (confidence: 52.6%)\n",
      "      Prob UP: 47.4% | Prob DOWN: 52.6%\n",
      "      Latest Price: ‚Çπ1,565.10\n",
      "\n",
      "[2/5] Processing TCS...\n",
      "   üìâ TCS: DOWN (confidence: 70.8%)\n",
      "      Prob UP: 29.2% | Prob DOWN: 70.8%\n",
      "      Latest Price: ‚Çπ3,282.00\n",
      "\n",
      "[3/5] Processing INFY...\n",
      "   üìâ INFY: DOWN (confidence: 81.5%)\n",
      "      Prob UP: 18.5% | Prob DOWN: 81.5%\n",
      "      Latest Price: ‚Çπ1,638.70\n",
      "\n",
      "[4/5] Processing HDFCBANK...\n",
      "   üìà HDFCBANK: UP (confidence: 54.9%)\n",
      "      Prob UP: 54.9% | Prob DOWN: 45.1%\n",
      "      Latest Price: ‚Çπ985.50\n",
      "\n",
      "[5/5] Processing ICICIBANK...\n",
      "   üìâ ICICIBANK: DOWN (confidence: 55.0%)\n",
      "      Prob UP: 45.0% | Prob DOWN: 55.0%\n",
      "      Latest Price: ‚Çπ1,354.10\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PREDICTION SUMMARY\n",
      "================================================================================\n",
      "Total stocks:            5\n",
      "Successful predictions:  5\n",
      "Failed predictions:      0\n",
      "\n",
      "Direction Breakdown:\n",
      "  üìà Predicted UP:         1\n",
      "  üìâ Predicted DOWN:       4\n",
      "\n",
      "Average Confidence:      63.0%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "üìä DETAILED RESULTS TABLE:\n",
      "====================================================================================================\n",
      "   symbol direction confidence probability_up probability_down latest_close  status\n",
      " RELIANCE      DOWN      52.6%          47.4%            52.6%    ‚Çπ1,565.10 SUCCESS\n",
      "      TCS      DOWN      70.8%          29.2%            70.8%    ‚Çπ3,282.00 SUCCESS\n",
      "     INFY      DOWN      81.5%          18.5%            81.5%    ‚Çπ1,638.70 SUCCESS\n",
      " HDFCBANK        UP      54.9%          54.9%            45.1%      ‚Çπ985.50 SUCCESS\n",
      "ICICIBANK      DOWN      55.0%          45.0%            55.0%    ‚Çπ1,354.10 SUCCESS\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "üìà STOCKS PREDICTED TO GO UP (sorted by confidence):\n",
      "================================================================================\n",
      "  HDFCBANK     | Price: ‚Çπ  985.50 | Confidence: 54.9% | Prob UP: 54.9%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "üìâ STOCKS PREDICTED TO GO DOWN (sorted by confidence):\n",
      "================================================================================\n",
      "  INFY         | Price: ‚Çπ1,638.70 | Confidence: 81.5% | Prob DOWN: 81.5%\n",
      "  TCS          | Price: ‚Çπ3,282.00 | Confidence: 70.8% | Prob DOWN: 70.8%\n",
      "  ICICIBANK    | Price: ‚Çπ1,354.10 | Confidence: 55.0% | Prob DOWN: 55.0%\n",
      "  RELIANCE     | Price: ‚Çπ1,565.10 | Confidence: 52.6% | Prob DOWN: 52.6%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "‚ö†Ô∏è  No stocks with ‚â•70% confidence for UP prediction\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for all LLM-recommended stocks\n",
    "if model is not None and scaler is not None:\n",
    "    results = predict_llm_recommendations(\n",
    "        stock_symbols=llm_recommendations,\n",
    "        model=model,\n",
    "        scaler=scaler\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüìä DETAILED RESULTS TABLE:\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # Display formatted table\n",
    "    display_cols = ['symbol', 'direction', 'confidence', 'probability_up', 'probability_down', 'latest_close', 'status']\n",
    "    display_df = results[display_cols].copy()\n",
    "    \n",
    "    # Format columns\n",
    "    if len(display_df[display_df['status'] == 'SUCCESS']) > 0:\n",
    "        display_df.loc[display_df['status'] == 'SUCCESS', 'confidence'] = display_df.loc[display_df['status'] == 'SUCCESS', 'confidence'].apply(lambda x: f\"{x:.1%}\" if pd.notnull(x) else 'N/A')\n",
    "        display_df.loc[display_df['status'] == 'SUCCESS', 'probability_up'] = display_df.loc[display_df['status'] == 'SUCCESS', 'probability_up'].apply(lambda x: f\"{x:.1%}\" if pd.notnull(x) else 'N/A')\n",
    "        display_df.loc[display_df['status'] == 'SUCCESS', 'probability_down'] = display_df.loc[display_df['status'] == 'SUCCESS', 'probability_down'].apply(lambda x: f\"{x:.1%}\" if pd.notnull(x) else 'N/A')\n",
    "        display_df.loc[display_df['status'] == 'SUCCESS', 'latest_close'] = display_df.loc[display_df['status'] == 'SUCCESS', 'latest_close'].apply(lambda x: f\"‚Çπ{x:,.2f}\" if pd.notnull(x) else 'N/A')\n",
    "    \n",
    "    print(display_df.to_string(index=False))\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # Separate UP and DOWN predictions\n",
    "    up_stocks = results[results['direction'] == 'UP'].sort_values('confidence', ascending=False)\n",
    "    down_stocks = results[results['direction'] == 'DOWN'].sort_values('confidence', ascending=False)\n",
    "    \n",
    "    if len(up_stocks) > 0:\n",
    "        print(\"\\n\\nüìà STOCKS PREDICTED TO GO UP (sorted by confidence):\")\n",
    "        print(\"=\" * 80)\n",
    "        for _, row in up_stocks.iterrows():\n",
    "            print(f\"  {row['symbol']:<12} | Price: ‚Çπ{row['latest_close']:>8,.2f} | Confidence: {row['confidence']:>5.1%} | Prob UP: {row['probability_up']:.1%}\")\n",
    "        print(\"=\" * 80)\n",
    "    \n",
    "    if len(down_stocks) > 0:\n",
    "        print(\"\\n\\nüìâ STOCKS PREDICTED TO GO DOWN (sorted by confidence):\")\n",
    "        print(\"=\" * 80)\n",
    "        for _, row in down_stocks.iterrows():\n",
    "            print(f\"  {row['symbol']:<12} | Price: ‚Çπ{row['latest_close']:>8,.2f} | Confidence: {row['confidence']:>5.1%} | Prob DOWN: {row['probability_down']:.1%}\")\n",
    "        print(\"=\" * 80)\n",
    "    \n",
    "    # Recommendation based on high confidence UP predictions\n",
    "    high_conf_up = results[(results['direction'] == 'UP') & (results['confidence'] >= 0.70)].sort_values('confidence', ascending=False)\n",
    "    \n",
    "    if len(high_conf_up) > 0:\n",
    "        print(\"\\n\\nüí° HIGH CONFIDENCE UP PREDICTIONS (‚â•70%):\")\n",
    "        print(\"=\" * 80)\n",
    "        print(\"These stocks have the strongest bullish signals:\")\n",
    "        for _, row in high_conf_up.iterrows():\n",
    "            print(f\"  {row['symbol']:<12} | Price: ‚Çπ{row['latest_close']:>8,.2f} | Confidence: {row['confidence']:>5.1%}\")\n",
    "        print(\"=\" * 80)\n",
    "    else:\n",
    "        print(\"\\n\\n‚ö†Ô∏è  No stocks with ‚â•70% confidence for UP prediction\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Model not loaded. Please run notebook 09 first and save the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Save Filtered Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All predictions saved to: data/predictions/ml_predictions_20251222_180522.csv\n"
     ]
    }
   ],
   "source": [
    "# Save all predictions to CSV\n",
    "if model is not None and scaler is not None:\n",
    "    output_dir = Path(\"data/predictions\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = output_dir / f\"ml_predictions_{timestamp}.csv\"\n",
    "    \n",
    "    results.to_csv(output_file, index=False)\n",
    "    print(f\"\\n‚úÖ All predictions saved to: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock-curator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
