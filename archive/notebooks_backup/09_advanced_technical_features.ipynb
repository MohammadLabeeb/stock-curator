{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Technical Features for Stock Direction Prediction\n",
    "\n",
    "## Goal\n",
    "Improve directional accuracy from 58.81% to >60% by adding:\n",
    "1. **15 advanced technical features** (market context, momentum, volume, statistical)\n",
    "2. **XGBoost ensemble** with Linear model (70-30 weighted)\n",
    "3. **Class weighting** for balanced predictions\n",
    "\n",
    "## Baseline\n",
    "- Model: Linear Regression + Logistic Regression\n",
    "- Accuracy: 58.81%\n",
    "- Sharpe: 0.2095\n",
    "- Features: 60-day window Ã— 32 technical indicators\n",
    "\n",
    "## Target\n",
    "- Accuracy: >60%\n",
    "- Maintain Sharpe â‰¥0.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully\n",
      "XGBoost version: 3.1.1\n",
      "Pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Progress bars\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# API requests (for NIFTY 50 fetching)\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… All libraries imported successfully\")\n",
    "print(f\"XGBoost version: {xgb.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: data/processed/stock_data\n",
      "Models directory: models\n",
      "MLflow tracking: mlruns\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "WINDOW_SIZE = 60          # Input: past 60 days of features\n",
    "HORIZON = 7               # Output: predict 7-day ahead return & direction\n",
    "TEST_STOCK_RATIO = 0.2    # 20% of stocks for testing\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path(\"data/processed/stock_data\")\n",
    "MODELS_DIR = Path(\"models\")\n",
    "MLFLOW_DIR = Path(\"mlruns\")\n",
    "\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Models directory: {MODELS_DIR}\")\n",
    "print(f\"MLflow tracking: {MLFLOW_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Experiment: stock-return-prediction-multihorizon\n",
      "Experiment ID: 785296905155056667\n",
      "Artifact Location: file:///home/labeeb/Desktop/stock-curator/mlruns/785296905155056667\n"
     ]
    }
   ],
   "source": [
    "# MLflow Setup\n",
    "mlflow.set_tracking_uri(f\"file://{MLFLOW_DIR.absolute()}\")\n",
    "mlflow.set_experiment(\"stock-return-prediction-multihorizon\")\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(\"stock-return-prediction-multihorizon\")\n",
    "print(f\"MLflow Experiment: {experiment.name}\")\n",
    "print(f\"Experiment ID: {experiment.experiment_id}\")\n",
    "print(f\"Artifact Location: {experiment.artifact_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98 stock CSV files\n",
      "\n",
      "First 5 files:\n",
      "  - ABBOTINDIA_historical.csv\n",
      "  - ABB_historical.csv\n",
      "  - ADANIENT_historical.csv\n",
      "  - ADANIGREEN_historical.csv\n",
      "  - ADANIPORTS_historical.csv\n"
     ]
    }
   ],
   "source": [
    "# Load all stock CSV files\n",
    "csv_files = sorted(glob.glob(str(DATA_DIR / \"*_historical.csv\")))\n",
    "\n",
    "print(f\"Found {len(csv_files)} stock CSV files\")\n",
    "print(f\"\\nFirst 5 files:\")\n",
    "for f in csv_files[:5]:\n",
    "    print(f\"  - {Path(f).name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 98 stocks successfully\n"
     ]
    }
   ],
   "source": [
    "def load_stock_data(file_path):\n",
    "    \"\"\"\n",
    "    Load a single stock CSV and preprocess it.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "    df_clean = df.dropna()\n",
    "    \n",
    "    # Need at least WINDOW_SIZE + HORIZON rows\n",
    "    if len(df_clean) < WINDOW_SIZE + HORIZON:\n",
    "        return None\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "\n",
    "# Load all stocks\n",
    "stock_data = {}\n",
    "skipped = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    symbol = Path(file_path).stem.replace('_historical', '')\n",
    "    df = load_stock_data(file_path)\n",
    "    \n",
    "    if df is not None:\n",
    "        stock_data[symbol] = df\n",
    "    else:\n",
    "        skipped.append(symbol)\n",
    "\n",
    "print(f\"Loaded {len(stock_data)} stocks successfully\")\n",
    "if skipped:\n",
    "    print(f\"Skipped {len(skipped)} stocks: {skipped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Stock: ABBOTINDIA\n",
      "Shape: (447, 28)\n",
      "Date Range: 2024-01-15 00:00:00+05:30 to 2025-10-31 00:00:00+05:30\n",
      "\n",
      "Columns (28):\n",
      "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'OI', 'SMA_5', 'SMA_10', 'SMA_20', 'SMA_50', 'EMA_12', 'EMA_26', 'MACD', 'MACD_Signal', 'MACD_Hist', 'RSI', 'BB_Middle', 'BB_Upper', 'BB_Lower', 'Volume_SMA_20', 'Volume_Ratio', 'Daily_Return', 'Price_Range', 'Price_Change', 'Symbol', 'Name', 'ISIN']\n",
      "\n",
      "First 3 rows:\n",
      "                        Date     Open      High       Low     Close  Volume  \\\n",
      "49 2024-01-15 00:00:00+05:30  25700.0  26381.65  25700.00  26210.45   33616   \n",
      "50 2024-01-16 00:00:00+05:30  26220.0  26305.90  25601.00  25806.50   51548   \n",
      "51 2024-01-17 00:00:00+05:30  25600.0  26139.95  25546.15  25730.70   15925   \n",
      "\n",
      "    OI     SMA_5     SMA_10      SMA_20  ...      BB_Upper      BB_Lower  \\\n",
      "49   0  25228.03  24418.650  23511.0825  ...  25865.034135  21157.130865   \n",
      "50   0  25542.95  24666.575  23662.3925  ...  26200.405545  21124.379455   \n",
      "51   0  25767.24  24878.985  23803.8150  ...  26475.193369  21132.436631   \n",
      "\n",
      "    Volume_SMA_20  Volume_Ratio  Daily_Return  Price_Range  Price_Change  \\\n",
      "49       24615.75      1.365630      0.017925       681.65        510.45   \n",
      "50       26163.95      1.970192     -0.015412       704.90       -413.50   \n",
      "51       26361.10      0.604110     -0.002937       593.80        130.70   \n",
      "\n",
      "        Symbol                  Name          ISIN  \n",
      "49  ABBOTINDIA  ABBOTT INDIA LIMITED  INE358A01014  \n",
      "50  ABBOTINDIA  ABBOTT INDIA LIMITED  INE358A01014  \n",
      "51  ABBOTINDIA  ABBOTT INDIA LIMITED  INE358A01014  \n",
      "\n",
      "[3 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Inspect sample data\n",
    "sample_symbol = list(stock_data.keys())[0]\n",
    "sample_df = stock_data[sample_symbol]\n",
    "\n",
    "print(f\"\\nSample Stock: {sample_symbol}\")\n",
    "print(f\"Shape: {sample_df.shape}\")\n",
    "print(f\"Date Range: {sample_df['Date'].min()} to {sample_df['Date'].max()}\")\n",
    "print(f\"\\nColumns ({len(sample_df.columns)}):\")\n",
    "print(sample_df.columns.tolist())\n",
    "print(f\"\\nFirst 3 rows:\")\n",
    "print(sample_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Feature Engineering - Add Return-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding return-based features...\n",
      "Feature engineering complete\n",
      "\n",
      "Updated feature count: 32\n"
     ]
    }
   ],
   "source": [
    "def add_return_features(df):\n",
    "    \"\"\"\n",
    "    Add return-based features for better stationarity.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Historical returns (already have Daily_Return = 1-day return)\n",
    "    df['Return_3d'] = df['Close'].pct_change(3) * 100\n",
    "    df['Return_5d'] = df['Close'].pct_change(5) * 100\n",
    "    df['Return_10d'] = df['Close'].pct_change(10) * 100\n",
    "    \n",
    "    # Log returns for better stationarity\n",
    "    df['Log_Return'] = np.log(df['Close'] / df['Close'].shift(1)) * 100\n",
    "    \n",
    "    # Volatility (rolling std of returns)\n",
    "    df['Volatility_5d'] = df['Daily_Return'].rolling(5).std()\n",
    "    df['Volatility_20d'] = df['Daily_Return'].rolling(20).std()\n",
    "    \n",
    "    # Momentum indicators\n",
    "    df['Momentum_10d'] = df['Close'] - df['Close'].shift(10)\n",
    "    df['Momentum_20d'] = df['Close'] - df['Close'].shift(20)\n",
    "    \n",
    "    # Drop NaN rows created by new features\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply to all stocks\n",
    "print(\"Adding return-based features...\")\n",
    "for symbol in stock_data.keys():\n",
    "    stock_data[symbol] = add_return_features(stock_data[symbol])\n",
    "\n",
    "print(f\"Feature engineering complete\")\n",
    "print(f\"\\nUpdated feature count: {len([col for col in stock_data[sample_symbol].columns if col not in ['Date', 'Symbol', 'Name', 'ISIN']])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.5 Fetch NIFTY 50 Index Data (for Market Context Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HTTP session created with retry logic\n"
     ]
    }
   ],
   "source": [
    "# NIFTY 50 configuration\n",
    "NIFTY50_INSTRUMENT_KEY = \"NSE_INDEX|Nifty 50\"\n",
    "UPSTOX_ACCESS_TOKEN = os.getenv(\"UPSTOX_ACCESS_TOKEN\")\n",
    "\n",
    "def create_session_with_retries(retries=3, backoff_factor=0.3):\n",
    "    \"\"\"Create a requests session with retry logic\"\"\"\n",
    "    session = requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=(500, 502, 504),\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "session = create_session_with_retries()\n",
    "print(\"âœ… HTTP session created with retry logic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… fetch_nifty50_data() function defined\n"
     ]
    }
   ],
   "source": [
    "def fetch_nifty50_data(start_date, end_date, access_token=None):\n",
    "    \"\"\"\n",
    "    Fetch NIFTY 50 index historical data\n",
    "\n",
    "    Args:\n",
    "        start_date: Start date (YYYY-MM-DD)\n",
    "        end_date: End date (YYYY-MM-DD)\n",
    "        access_token: Upstox API token\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with Date and Close columns\n",
    "    \"\"\"\n",
    "    if access_token is None:\n",
    "        access_token = UPSTOX_ACCESS_TOKEN\n",
    "\n",
    "    if not access_token:\n",
    "        print(\"âš ï¸  Error: UPSTOX_ACCESS_TOKEN not set\")\n",
    "        return None\n",
    "\n",
    "    # Build URL for NIFTY 50\n",
    "    instrument_key_encoded = \"NSE_INDEX%7CNifty%2050\"  # URL encoded\n",
    "    url = f\"https://api.upstox.com/v3/historical-candle/{instrument_key_encoded}/days/1/{end_date}/{start_date}\"\n",
    "\n",
    "    headers = {\n",
    "        'Accept': 'application/json',\n",
    "        'Authorization': f'Bearer {access_token}'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, headers=headers, timeout=15)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "\n",
    "            if data.get('status') == 'success' and 'data' in data:\n",
    "                candles = data['data'].get('candles', [])\n",
    "\n",
    "                if not candles:\n",
    "                    print(\"âš ï¸  No NIFTY 50 data returned\")\n",
    "                    return None\n",
    "\n",
    "                # Convert to DataFrame\n",
    "                df = pd.DataFrame(candles, columns=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'OI'])\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "                df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "                # Keep only Date and Close for market context\n",
    "                df = df[['Date', 'Close']]\n",
    "                df.rename(columns={'Close': 'Nifty50_Close'}, inplace=True)\n",
    "\n",
    "                return df\n",
    "            else:\n",
    "                print(f\"âš ï¸  API error: {data.get('message', 'Unknown error')}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"âš ï¸  HTTP {response.status_code}: {response.text[:200]}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Exception: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ… fetch_nifty50_data() function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching NIFTY 50 data from 2024-02-13 to 2025-10-31...\n",
      "âœ… Fetched 427 days of NIFTY 50 data\n",
      "   Date range: 2024-02-13 00:00:00+05:30 to 2025-10-31 00:00:00+05:30\n",
      "\n",
      "First 3 rows:\n",
      "                       Date  Nifty50_Close\n",
      "0 2024-02-13 00:00:00+05:30       21743.25\n",
      "1 2024-02-14 00:00:00+05:30       21840.05\n",
      "2 2024-02-15 00:00:00+05:30       21910.75\n"
     ]
    }
   ],
   "source": [
    "# Fetch NIFTY 50 data for the same date range as stocks\n",
    "sample_stock = list(stock_data.values())[0]\n",
    "start_date = sample_stock['Date'].min().strftime('%Y-%m-%d')\n",
    "end_date = sample_stock['Date'].max().strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Fetching NIFTY 50 data from {start_date} to {end_date}...\")\n",
    "\n",
    "nifty50_df = fetch_nifty50_data(start_date, end_date)\n",
    "\n",
    "if nifty50_df is not None:\n",
    "    print(f\"âœ… Fetched {len(nifty50_df)} days of NIFTY 50 data\")\n",
    "    print(f\"   Date range: {nifty50_df['Date'].min()} to {nifty50_df['Date'].max()}\")\n",
    "    print(f\"\\nFirst 3 rows:\")\n",
    "    print(nifty50_df.head(3))\n",
    "else:\n",
    "    print(\"âš ï¸  Failed to fetch NIFTY 50 data\")\n",
    "    print(\"   Will skip market context features (3 features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.6 Advanced Technical Feature Engineering\n",
    "\n",
    "Adding 15 new features across 4 categories:\n",
    "1. **Market Context (3)**: Relative strength, correlation, market regime\n",
    "2. **Momentum & Mean Reversion (6)**: RSI divergence, MACD crossover, BB squeeze, etc.\n",
    "3. **Volume & Liquidity (3)**: Volume price trend, on-balance volume, volume breakout\n",
    "4. **Statistical (3)**: Returns skewness, kurtosis, Hurst exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… add_advanced_technical_features() function defined\n"
     ]
    }
   ],
   "source": [
    "def add_advanced_technical_features(df, nifty50_df=None):\n",
    "    \"\"\"\n",
    "    Add 15 advanced technical features to stock DataFrame\n",
    "\n",
    "    Args:\n",
    "        df: Stock DataFrame with existing 32 features\n",
    "        nifty50_df: NIFTY 50 DataFrame with Date and Nifty50_Close columns\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with up to 47 features (32 + 15, or 32 + 12 if no NIFTY data)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # ========== MARKET CONTEXT FEATURES (3) ==========\n",
    "    if nifty50_df is not None:\n",
    "        # Merge with NIFTY 50 data\n",
    "        df = df.merge(nifty50_df, on='Date', how='left')\n",
    "\n",
    "        # 1. Relative strength to NIFTY 50\n",
    "        df['Nifty50_Return'] = df['Nifty50_Close'].pct_change() * 100\n",
    "        df['relative_strength_to_nifty50'] = df['Daily_Return'] - df['Nifty50_Return']\n",
    "\n",
    "        # 2. Correlation to NIFTY 50 (20-day rolling)\n",
    "        df['correlation_to_nifty50_20d'] = df['Daily_Return'].rolling(20).corr(df['Nifty50_Return'])\n",
    "\n",
    "        # 3. Market regime (based on NIFTY 50 trend)\n",
    "        nifty_sma_20 = df['Nifty50_Close'].rolling(20).mean()\n",
    "        nifty_sma_50 = df['Nifty50_Close'].rolling(50).mean()\n",
    "        df['market_regime'] = 0  # Sideways\n",
    "        df.loc[nifty_sma_20 > nifty_sma_50, 'market_regime'] = 1  # Bull\n",
    "        df.loc[nifty_sma_20 < nifty_sma_50, 'market_regime'] = -1  # Bear\n",
    "\n",
    "        # Drop temporary columns\n",
    "        df.drop(columns=['Nifty50_Close', 'Nifty50_Return'], inplace=True)\n",
    "    else:\n",
    "        # Set to NaN if NIFTY data not available\n",
    "        df['relative_strength_to_nifty50'] = np.nan\n",
    "        df['correlation_to_nifty50_20d'] = np.nan\n",
    "        df['market_regime'] = 0  # Default to sideways\n",
    "\n",
    "    # ========== MOMENTUM & MEAN REVERSION FEATURES (6) ==========\n",
    "\n",
    "    # 4. RSI divergence (RSI trend vs price trend)\n",
    "    rsi_change = df['RSI'].diff(5)\n",
    "    price_change = df['Close'].pct_change(5)\n",
    "    df['rsi_divergence'] = np.sign(rsi_change) - np.sign(price_change)\n",
    "\n",
    "    # 5. MACD crossover signal\n",
    "    df['macd_crossover_signal'] = 0\n",
    "    macd_cross_up = (df['MACD'] > df['MACD_Signal']) & (df['MACD'].shift(1) <= df['MACD_Signal'].shift(1))\n",
    "    macd_cross_down = (df['MACD'] < df['MACD_Signal']) & (df['MACD'].shift(1) >= df['MACD_Signal'].shift(1))\n",
    "    df.loc[macd_cross_up, 'macd_crossover_signal'] = 1\n",
    "    df.loc[macd_cross_down, 'macd_crossover_signal'] = -1\n",
    "\n",
    "    # 6. Bollinger Band squeeze (volatility compression)\n",
    "    bb_width = (df['BB_Upper'] - df['BB_Lower']) / df['BB_Middle']\n",
    "    df['bb_squeeze'] = bb_width.rolling(20).apply(lambda x: (x.iloc[-1] - x.min()) / (x.max() - x.min() + 1e-8), raw=False)\n",
    "\n",
    "    # 7. Price vs SMA50 percentage\n",
    "    df['price_vs_sma50_pct'] = ((df['Close'] - df['SMA_50']) / df['SMA_50']) * 100\n",
    "\n",
    "    # 8. Momentum strength (rate of change in momentum)\n",
    "    df['momentum_strength'] = df['Momentum_10d'].diff(5)\n",
    "\n",
    "    # 9. Support/Resistance distance (distance to 20-day high/low)\n",
    "    high_20 = df['High'].rolling(20).max()\n",
    "    low_20 = df['Low'].rolling(20).min()\n",
    "    df['support_resistance_distance'] = np.where(\n",
    "        df['Close'] > df['Close'].shift(1),\n",
    "        (high_20 - df['Close']) / df['Close'],  # Distance to resistance\n",
    "        (df['Close'] - low_20) / df['Close']     # Distance to support\n",
    "    )\n",
    "\n",
    "    # ========== VOLUME & LIQUIDITY FEATURES (3) ==========\n",
    "\n",
    "    # 10. Volume Price Trend (cumulative volume Ã— price direction)\n",
    "    price_direction = np.sign(df['Close'].diff())\n",
    "    df['volume_price_trend'] = (df['Volume'] * price_direction).cumsum()\n",
    "\n",
    "    # 11. On-Balance Volume (cumulative volume flow)\n",
    "    obv = np.where(df['Close'] > df['Close'].shift(1), df['Volume'],\n",
    "                   np.where(df['Close'] < df['Close'].shift(1), -df['Volume'], 0))\n",
    "    df['on_balance_volume'] = obv.cumsum()\n",
    "\n",
    "    # 12. Volume breakout (binary: volume > 2Ã— average)\n",
    "    df['volume_breakout'] = (df['Volume'] > 2 * df['Volume_SMA_20']).astype(int)\n",
    "\n",
    "    # ========== STATISTICAL FEATURES (3) ==========\n",
    "\n",
    "    # 13. Returns skewness (20-day)\n",
    "    df['returns_skewness_20d'] = df['Daily_Return'].rolling(20).skew()\n",
    "\n",
    "    # 14. Returns kurtosis (20-day) - tail risk\n",
    "    df['returns_kurtosis_20d'] = df['Daily_Return'].rolling(20).kurt()\n",
    "\n",
    "    # 15. Hurst exponent (trend persistence over 60 days)\n",
    "    def calculate_hurst(ts, lags=range(2, 20)):\n",
    "        \"\"\"Calculate Hurst exponent - measures trend persistence\"\"\"\n",
    "        if len(ts) < max(lags):\n",
    "            return 0.5  # Random walk\n",
    "\n",
    "        tau = []\n",
    "        lagvec = []\n",
    "\n",
    "        for lag in lags:\n",
    "            # Calculate standard deviation of lagged differences\n",
    "            pp = np.subtract(ts[lag:], ts[:-lag])\n",
    "            lagvec.append(lag)\n",
    "            tau.append(np.std(pp))\n",
    "\n",
    "        # Linear fit in log-log scale\n",
    "        try:\n",
    "            poly = np.polyfit(np.log(lagvec), np.log(tau), 1)\n",
    "            return poly[0]  # Slope = Hurst exponent\n",
    "        except:\n",
    "            return 0.5\n",
    "\n",
    "    df['hurst_exponent'] = df['Close'].rolling(60).apply(lambda x: calculate_hurst(x.values), raw=False)\n",
    "\n",
    "    # Drop NaN rows created by new features\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"âœ… add_advanced_technical_features() function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 15 advanced technical features to all stocks...\n",
      "This may take a few minutes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acf5aca933844e587fcc426bb1d597f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing stocks:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Advanced feature engineering complete!\n",
      "\n",
      "ðŸ“Š Feature count: 47 features\n",
      "   Previous: 32 features\n",
      "   New: 15 features added\n",
      "\n",
      "ðŸ“ New features added:\n",
      "    1. relative_strength_to_nifty50\n",
      "    2. correlation_to_nifty50_20d\n",
      "    3. market_regime\n",
      "    4. rsi_divergence\n",
      "    5. macd_crossover_signal\n",
      "    6. bb_squeeze\n",
      "    7. price_vs_sma50_pct\n",
      "    8. momentum_strength\n",
      "    9. support_resistance_distance\n",
      "   10. volume_price_trend\n",
      "   11. on_balance_volume\n",
      "   12. volume_breakout\n",
      "   13. returns_skewness_20d\n",
      "   14. returns_kurtosis_20d\n",
      "   15. hurst_exponent\n"
     ]
    }
   ],
   "source": [
    "# Apply advanced features to all stocks\n",
    "print(\"Adding 15 advanced technical features to all stocks...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "for symbol in tqdm(stock_data.keys(), desc=\"Processing stocks\"):\n",
    "    stock_data[symbol] = add_advanced_technical_features(\n",
    "        stock_data[symbol],\n",
    "        nifty50_df if nifty50_df is not None else None\n",
    "    )\n",
    "\n",
    "print(\"\\nâœ… Advanced feature engineering complete!\")\n",
    "\n",
    "# Check feature count\n",
    "sample_symbol = list(stock_data.keys())[0]\n",
    "exclude_cols = ['Date', 'Symbol', 'Name', 'ISIN']\n",
    "feature_cols = [col for col in stock_data[sample_symbol].columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"\\nðŸ“Š Feature count: {len(feature_cols)} features\")\n",
    "print(f\"   Previous: 32 features\")\n",
    "print(f\"   New: {len(feature_cols) - 32} features added\")\n",
    "\n",
    "# Print new features\n",
    "new_features = [col for col in feature_cols if col not in [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume', 'OI', 'SMA_5', 'SMA_10', 'SMA_20', 'SMA_50',\n",
    "    'EMA_12', 'EMA_26', 'MACD', 'MACD_Signal', 'MACD_Hist', 'RSI', 'BB_Middle', 'BB_Upper',\n",
    "    'BB_Lower', 'Volume_SMA_20', 'Volume_Ratio', 'Daily_Return', 'Price_Range', 'Price_Change',\n",
    "    'Return_3d', 'Return_5d', 'Return_10d', 'Log_Return', 'Volatility_5d', 'Volatility_20d',\n",
    "    'Momentum_10d', 'Momentum_20d'\n",
    "]]\n",
    "\n",
    "print(f\"\\nðŸ“ New features added:\")\n",
    "for i, feat in enumerate(new_features, 1):\n",
    "    print(f\"   {i:2d}. {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Create Target Variables: Returns & Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Sequence Creation on ABBOTINDIA:\n",
      "  X shape:          (302, 60, 47)  <- (samples, window_size, features)\n",
      "  y_return shape:   (302,)  <- 7-day return %\n",
      "  y_direction shape: (302,)  <- UP/DOWN (1/0)\n",
      "\n",
      "  Example:\n",
      "    Return:    0.43%\n",
      "    Direction: 1 (UP)\n",
      "\n",
      "  Class distribution:\n",
      "    UP (1):   142 (47.0%)\n",
      "    DOWN (0): 160 (53.0%)\n"
     ]
    }
   ],
   "source": [
    "def create_sequences_with_returns(df, window_size=60, horizon=7):\n",
    "    \"\"\"\n",
    "    Create sliding window sequences with return and direction targets.\n",
    "    \n",
    "    Returns:\n",
    "        X: (n_samples, window_size, n_features) - input features\n",
    "        y_return: (n_samples,) - 7-day cumulative return %\n",
    "        y_direction: (n_samples,) - 1 if UP, 0 if DOWN\n",
    "    \"\"\"\n",
    "    features = df[feature_cols].values\n",
    "    close_prices = df['Close'].values\n",
    "    \n",
    "    X, y_return, y_direction = [], [], []\n",
    "    \n",
    "    for i in range(len(df) - window_size - horizon + 1):\n",
    "        # Input: past window_size days of all features\n",
    "        X.append(features[i:i + window_size])\n",
    "        \n",
    "        # Current close price (last day of input window)\n",
    "        current_close = close_prices[i + window_size - 1]\n",
    "        \n",
    "        # Future close price (horizon days ahead)\n",
    "        future_close = close_prices[i + window_size + horizon - 1]\n",
    "        \n",
    "        # Calculate 7-day return percentage\n",
    "        return_pct = ((future_close - current_close) / current_close) * 100\n",
    "        y_return.append(return_pct)\n",
    "        \n",
    "        # Calculate direction (1 = UP, 0 = DOWN)\n",
    "        direction = 1 if future_close > current_close else 0\n",
    "        y_direction.append(direction)\n",
    "    \n",
    "    return np.array(X), np.array(y_return), np.array(y_direction)\n",
    "\n",
    "\n",
    "# Test on sample stock\n",
    "X_test, y_ret_test, y_dir_test = create_sequences_with_returns(stock_data[sample_symbol], WINDOW_SIZE, HORIZON)\n",
    "\n",
    "print(f\"\\nTest Sequence Creation on {sample_symbol}:\")\n",
    "print(f\"  X shape:          {X_test.shape}  <- (samples, window_size, features)\")\n",
    "print(f\"  y_return shape:   {y_ret_test.shape}  <- 7-day return %\")\n",
    "print(f\"  y_direction shape: {y_dir_test.shape}  <- UP/DOWN (1/0)\")\n",
    "print(f\"\\n  Example:\")\n",
    "print(f\"    Return:    {y_ret_test[0]:.2f}%\")\n",
    "print(f\"    Direction: {y_dir_test[0]} ({'UP' if y_dir_test[0] == 1 else 'DOWN'})\")\n",
    "print(f\"\\n  Class distribution:\")\n",
    "print(f\"    UP (1):   {np.sum(y_dir_test == 1)} ({np.mean(y_dir_test == 1)*100:.1f}%)\")\n",
    "print(f\"    DOWN (0): {np.sum(y_dir_test == 0)} ({np.mean(y_dir_test == 0)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Train/Test Split & Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stock Split:\n",
      "  Training stocks: 79 (80.6%)\n",
      "  Test stocks:     19 (19.4%)\n"
     ]
    }
   ],
   "source": [
    "# Split stocks into train and test sets\n",
    "stock_symbols = list(stock_data.keys())\n",
    "n_test_stocks = int(len(stock_symbols) * TEST_STOCK_RATIO)\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "shuffled_symbols = np.random.permutation(stock_symbols)\n",
    "\n",
    "train_symbols = shuffled_symbols[:-n_test_stocks]\n",
    "test_symbols = shuffled_symbols[-n_test_stocks:]\n",
    "\n",
    "print(f\"\\nStock Split:\")\n",
    "print(f\"  Training stocks: {len(train_symbols)} ({len(train_symbols)/len(stock_symbols)*100:.1f}%)\")\n",
    "print(f\"  Test stocks:     {len(test_symbols)} ({len(test_symbols)/len(stock_symbols)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating sequences for training stocks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84a6694d7e9403da3154621bc3593ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing train stocks:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set:\n",
      "  X_train: (23858, 60, 47)\n",
      "  y_return_train: (23858,)\n",
      "  y_direction_train: (23858,)\n",
      "  UP/DOWN ratio: 50.1% UP\n"
     ]
    }
   ],
   "source": [
    "# Create sequences for training stocks\n",
    "print(\"\\nCreating sequences for training stocks...\")\n",
    "X_train_list, y_return_train_list, y_dir_train_list = [], [], []\n",
    "\n",
    "for symbol in tqdm(train_symbols, desc=\"Processing train stocks\"):\n",
    "    df = stock_data[symbol]\n",
    "    X, y_ret, y_dir = create_sequences_with_returns(df, WINDOW_SIZE, HORIZON)\n",
    "    X_train_list.append(X)\n",
    "    y_return_train_list.append(y_ret)\n",
    "    y_dir_train_list.append(y_dir)\n",
    "\n",
    "X_train = np.concatenate(X_train_list, axis=0)\n",
    "y_return_train = np.concatenate(y_return_train_list, axis=0)\n",
    "y_direction_train = np.concatenate(y_dir_train_list, axis=0)\n",
    "\n",
    "print(f\"\\nTraining set:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  y_return_train: {y_return_train.shape}\")\n",
    "print(f\"  y_direction_train: {y_direction_train.shape}\")\n",
    "print(f\"  UP/DOWN ratio: {np.mean(y_direction_train == 1)*100:.1f}% UP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating sequences for test stocks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc02a54916745c3b4f93eb791213aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing test stocks:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:\n",
      "  X_test: (5738, 60, 47)\n",
      "  y_return_test: (5738,)\n",
      "  y_direction_test: (5738,)\n",
      "  UP/DOWN ratio: 51.7% UP\n"
     ]
    }
   ],
   "source": [
    "# Create sequences for test stocks\n",
    "print(\"\\nCreating sequences for test stocks...\")\n",
    "X_test_list, y_return_test_list, y_dir_test_list = [], [], []\n",
    "\n",
    "for symbol in tqdm(test_symbols, desc=\"Processing test stocks\"):\n",
    "    df = stock_data[symbol]\n",
    "    X, y_ret, y_dir = create_sequences_with_returns(df, WINDOW_SIZE, HORIZON)\n",
    "    X_test_list.append(X)\n",
    "    y_return_test_list.append(y_ret)\n",
    "    y_dir_test_list.append(y_dir)\n",
    "\n",
    "X_test = np.concatenate(X_test_list, axis=0)\n",
    "y_return_test = np.concatenate(y_return_test_list, axis=0)\n",
    "y_direction_test = np.concatenate(y_dir_test_list, axis=0)\n",
    "\n",
    "print(f\"\\nTest set:\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  y_return_test: {y_return_test.shape}\")\n",
    "print(f\"  y_direction_test: {y_direction_test.shape}\")\n",
    "print(f\"  UP/DOWN ratio: {np.mean(y_direction_test == 1)*100:.1f}% UP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling features...\n",
      "  X_train_scaled: (23858, 60, 47)\n",
      "  X_test_scaled:  (5738, 60, 47)\n",
      "\n",
      "  Targets NOT scaled (returns are already normalized)\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling (IMPORTANT: Don't scale targets - returns are already normalized)\n",
    "print(\"\\nScaling features...\")\n",
    "\n",
    "n_train_samples, window_size, n_features = X_train.shape\n",
    "n_test_samples = X_test.shape[0]\n",
    "\n",
    "X_train_2d = X_train.reshape(-1, n_features)\n",
    "X_test_2d = X_test.reshape(-1, n_features)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled_2d = scaler_X.fit_transform(X_train_2d)\n",
    "X_test_scaled_2d = scaler_X.transform(X_test_2d)\n",
    "\n",
    "X_train_scaled = X_train_scaled_2d.reshape(n_train_samples, window_size, n_features)\n",
    "X_test_scaled = X_test_scaled_2d.reshape(n_test_samples, window_size, n_features)\n",
    "\n",
    "print(f\"  X_train_scaled: {X_train_scaled.shape}\")\n",
    "print(f\"  X_test_scaled:  {X_test_scaled.shape}\")\n",
    "print(f\"\\n  Targets NOT scaled (returns are already normalized)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Helper Functions for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def calculate_regression_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate metrics for return prediction (regression).\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (np.abs(y_true) + 1e-8))) * 100\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'mape': mape\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_classification_metrics(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"Calculate metrics for direction prediction (classification).\"\"\"\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1': f1\n",
    "    }\n",
    "    \n",
    "    if y_pred_proba is not None:\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, y_pred_proba)\n",
    "            metrics['auc'] = auc\n",
    "        except:\n",
    "            metrics['auc'] = 0.0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def calculate_sharpe_ratio(returns, risk_free_rate=0.0):\n",
    "    \"\"\"Calculate Sharpe ratio from returns.\"\"\"\n",
    "    if len(returns) == 0 or np.std(returns) == 0:\n",
    "        return 0.0\n",
    "    return (np.mean(returns) - risk_free_rate) / np.std(returns)\n",
    "\n",
    "\n",
    "def simulate_trading(y_direction_true, y_direction_pred, y_return_true,\n",
    "                    position_size=1000, transaction_cost=0.001):\n",
    "    \"\"\"\n",
    "    Simulate trading with fair capital allocation for model comparison.\n",
    "\n",
    "    Key Principle:\n",
    "    - Each trade gets the SAME position size (â‚¹1,000 by default)\n",
    "    - Initial capital = position_size Ã— number of UP predictions\n",
    "    - This ensures models with different trade frequencies are fairly compared\n",
    "    - Total return % is directly comparable across models\n",
    "\n",
    "    Strategy:\n",
    "    - If predict UP (1): BUY with position_size and hold for 7 days\n",
    "    - If predict DOWN (0): Stay in cash (no trade)\n",
    "\n",
    "    Args:\n",
    "        position_size: Amount invested per trade (default â‚¹1,000)\n",
    "        transaction_cost: Transaction cost as fraction (0.001 = 0.1%)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with trading performance metrics\n",
    "    \"\"\"\n",
    "    # Count number of UP predictions (trades we'll make)\n",
    "    n_trades = np.sum(y_direction_pred == 1)\n",
    "\n",
    "    if n_trades == 0:\n",
    "        return {\n",
    "            'initial_capital': 0,\n",
    "            'final_capital': 0,\n",
    "            'total_return_pct': 0,\n",
    "            'n_trades': 0,\n",
    "            'win_rate': 0,\n",
    "            'avg_return_per_trade': 0,\n",
    "            'sharpe_ratio': 0,\n",
    "            'trades': []\n",
    "        }\n",
    "\n",
    "    # Initial capital proportional to number of trades\n",
    "    initial_capital = position_size * n_trades\n",
    "\n",
    "    # Track all trades\n",
    "    trades = []\n",
    "    returns_list = []\n",
    "    wins = 0\n",
    "    total_pnl = 0\n",
    "\n",
    "    for i in range(len(y_direction_pred)):\n",
    "        pred_direction = y_direction_pred[i]\n",
    "        actual_return_pct = y_return_true[i]\n",
    "\n",
    "        # Only trade if we predict UP\n",
    "        if pred_direction == 1:\n",
    "            # Calculate net return after transaction costs\n",
    "            # Cost = 0.1% on buy + 0.1% on sell = 0.2% total\n",
    "            net_return_pct = actual_return_pct - (transaction_cost * 100 * 2)\n",
    "\n",
    "            # P&L for this trade\n",
    "            pnl = position_size * (net_return_pct / 100)\n",
    "            total_pnl += pnl\n",
    "\n",
    "            returns_list.append(net_return_pct)\n",
    "\n",
    "            if net_return_pct > 0:\n",
    "                wins += 1\n",
    "\n",
    "            trades.append({\n",
    "                'index': i,\n",
    "                'predicted': pred_direction,\n",
    "                'actual_direction': y_direction_true[i],\n",
    "                'return_pct': actual_return_pct,\n",
    "                'net_return': net_return_pct\n",
    "            })\n",
    "\n",
    "    # Final capital\n",
    "    final_capital = initial_capital + total_pnl\n",
    "\n",
    "    # Total return percentage\n",
    "    total_return_pct = (total_pnl / initial_capital) * 100\n",
    "\n",
    "    # Metrics\n",
    "    win_rate = wins / n_trades\n",
    "    avg_return_per_trade = np.mean(returns_list)\n",
    "    sharpe_ratio = calculate_sharpe_ratio(returns_list)\n",
    "\n",
    "    return {\n",
    "        'initial_capital': initial_capital,\n",
    "        'final_capital': final_capital,\n",
    "        'total_return_pct': total_return_pct,\n",
    "        'n_trades': n_trades,\n",
    "        'win_rate': win_rate,\n",
    "        'avg_return_per_trade': avg_return_per_trade,\n",
    "        'sharpe_ratio': sharpe_ratio,\n",
    "        'trades': trades\n",
    "    }\n",
    "\n",
    "\n",
    "def print_evaluation_summary(model_name, reg_metrics, clf_metrics, trading_metrics):\n",
    "    \"\"\"Print comprehensive evaluation summary.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Results for {model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    print(f\"\\n[REGRESSION] Return Prediction:\")\n",
    "    print(f\"  MAE:   {reg_metrics['mae']:.3f}%\")\n",
    "    print(f\"  RMSE:  {reg_metrics['rmse']:.3f}%\")\n",
    "    print(f\"  RÂ²:    {reg_metrics['r2']:.4f}\")\n",
    "    print(f\"  MAPE:  {reg_metrics['mape']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\n[CLASSIFICATION] Direction Prediction:\")\n",
    "    print(f\"  Accuracy:  {clf_metrics['accuracy']*100:.2f}%\")\n",
    "    print(f\"  Precision: {clf_metrics['precision']*100:.2f}%\")\n",
    "    print(f\"  Recall:    {clf_metrics['recall']*100:.2f}%\")\n",
    "    print(f\"  F1-Score:  {clf_metrics['f1']*100:.2f}%\")\n",
    "    if 'auc' in clf_metrics:\n",
    "        print(f\"  ROC-AUC:   {clf_metrics['auc']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n[TRADING SIMULATION]:\")\n",
    "    print(f\"  Initial Capital:   â‚¹{trading_metrics['initial_capital']:,.2f} ({trading_metrics['n_trades']} trades Ã— â‚¹1,000)\")\n",
    "    print(f\"  Final Capital:     â‚¹{trading_metrics['final_capital']:,.2f}\")\n",
    "    print(f\"  Total Return:      {trading_metrics['total_return_pct']:.2f}%\")\n",
    "    print(f\"  Number of Trades:  {trading_metrics['n_trades']}\")\n",
    "    print(f\"  Win Rate:          {trading_metrics['win_rate']*100:.2f}%\")\n",
    "    print(f\"  Avg Return/Trade:  {trading_metrics['avg_return_per_trade']:.3f}%\")\n",
    "    print(f\"  Sharpe Ratio:      {trading_metrics['sharpe_ratio']:.4f}\")\n",
    "    \n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "print(\"Evaluation helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Baseline Models (with Advanced Features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Linear Models with Class Weighting (Phase 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Linear Models with Class Weighting...\n",
      "\n",
      "Training Linear Regression for returns...\n",
      "Training Logistic Regression for direction (with class_weight='balanced')...\n",
      "\n",
      "======================================================================\n",
      "Results for Linear Models (Class Weighted)\n",
      "======================================================================\n",
      "\n",
      "[REGRESSION] Return Prediction:\n",
      "  MAE:   3.346%\n",
      "  RMSE:  4.376%\n",
      "  RÂ²:    0.1093\n",
      "  MAPE:  11463036.81%\n",
      "\n",
      "[CLASSIFICATION] Direction Prediction:\n",
      "  Accuracy:  63.47%\n",
      "  Precision: 65.99%\n",
      "  Recall:    60.52%\n",
      "  F1-Score:  63.14%\n",
      "  ROC-AUC:   0.6832\n",
      "\n",
      "[TRADING SIMULATION]:\n",
      "  Initial Capital:   â‚¹2,720,000.00 (2720 trades Ã— â‚¹1,000)\n",
      "  Final Capital:     â‚¹2,758,840.67\n",
      "  Total Return:      1.43%\n",
      "  Number of Trades:  2720\n",
      "  Win Rate:          63.93%\n",
      "  Avg Return/Trade:  1.428%\n",
      "  Sharpe Ratio:      0.3227\n",
      "======================================================================\n",
      "\n",
      "Training time: 213.82s\n",
      "Linear models complete\n"
     ]
    }
   ],
   "source": [
    "# Linear models with class_weight='balanced'\n",
    "print(\"Running Linear Models with Class Weighting...\\n\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Linear_ClassWeighted_47features\"):\n",
    "    mlflow.log_param(\"model_type\", \"Linear_ClassWeighted\")\n",
    "    mlflow.log_param(\"window_size\", WINDOW_SIZE)\n",
    "    mlflow.log_param(\"horizon\", HORIZON)\n",
    "    mlflow.log_param(\"num_features\", len(feature_cols))\n",
    "    mlflow.log_param(\"class_weight\", \"balanced\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Flatten inputs\n",
    "    X_train_flat = X_train_scaled.reshape(len(X_train_scaled), -1)\n",
    "    X_test_flat = X_test_scaled.reshape(len(X_test_scaled), -1)\n",
    "\n",
    "    # Train return predictor (regression)\n",
    "    print(\"Training Linear Regression for returns...\")\n",
    "    reg_model = LinearRegression()\n",
    "    reg_model.fit(X_train_flat, y_return_train)\n",
    "    y_return_pred = reg_model.predict(X_test_flat)\n",
    "\n",
    "    # Train direction predictor (classification) with CLASS WEIGHTING\n",
    "    print(\"Training Logistic Regression for direction (with class_weight='balanced')...\")\n",
    "    clf_model = LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=RANDOM_STATE,\n",
    "        class_weight='balanced'  # Phase 3: Class weighting\n",
    "    )\n",
    "    clf_model.fit(X_train_flat, y_direction_train)\n",
    "    y_direction_pred_linear = clf_model.predict(X_test_flat)\n",
    "    y_direction_pred_proba_linear = clf_model.predict_proba(X_test_flat)[:, 1]\n",
    "\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    # Evaluate\n",
    "    reg_metrics = calculate_regression_metrics(y_return_test, y_return_pred)\n",
    "    clf_metrics = calculate_classification_metrics(y_direction_test, y_direction_pred_linear, y_direction_pred_proba_linear)\n",
    "    trading_metrics = simulate_trading(y_direction_test, y_direction_pred_linear, y_return_test)\n",
    "\n",
    "    # Log to MLflow\n",
    "    for key, val in {**reg_metrics, **clf_metrics, **trading_metrics}.items():\n",
    "        if key != 'trades':\n",
    "            mlflow.log_metric(key, val)\n",
    "    mlflow.log_metric(\"train_time_seconds\", train_time)\n",
    "\n",
    "    # Save for later ensemble\n",
    "    linear_accuracy = clf_metrics['accuracy']\n",
    "    linear_sharpe = trading_metrics['sharpe_ratio']\n",
    "\n",
    "    print_evaluation_summary(\"Linear Models (Class Weighted)\", reg_metrics, clf_metrics, trading_metrics)\n",
    "    print(f\"Training time: {train_time:.2f}s\")\n",
    "\n",
    "print(\"Linear models complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 XGBoost Classifier (Phase 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running XGBoost Classifier...\n",
      "\n",
      "Training XGBoost for direction...\n",
      "\n",
      "======================================================================\n",
      "Results for XGBoost\n",
      "======================================================================\n",
      "\n",
      "[REGRESSION] Return Prediction:\n",
      "  MAE:   0.000%\n",
      "  RMSE:  0.000%\n",
      "  RÂ²:    0.0000\n",
      "  MAPE:  0.00%\n",
      "\n",
      "[CLASSIFICATION] Direction Prediction:\n",
      "  Accuracy:  70.08%\n",
      "  Precision: 73.10%\n",
      "  Recall:    66.62%\n",
      "  F1-Score:  69.71%\n",
      "  ROC-AUC:   0.7662\n",
      "\n",
      "[TRADING SIMULATION]:\n",
      "  Initial Capital:   â‚¹2,703,000.00 (2703 trades Ã— â‚¹1,000)\n",
      "  Final Capital:     â‚¹2,759,009.45\n",
      "  Total Return:      2.07%\n",
      "  Number of Trades:  2703\n",
      "  Win Rate:          70.81%\n",
      "  Avg Return/Trade:  2.072%\n",
      "  Sharpe Ratio:      0.4992\n",
      "======================================================================\n",
      "\n",
      "Training time: 109.94s\n",
      "XGBoost complete\n"
     ]
    }
   ],
   "source": [
    "# XGBoost for direction prediction\n",
    "print(\"\\nRunning XGBoost Classifier...\\n\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"XGBoost_47features\"):\n",
    "    mlflow.log_param(\"model_type\", \"XGBoost\")\n",
    "    mlflow.log_param(\"window_size\", WINDOW_SIZE)\n",
    "    mlflow.log_param(\"horizon\", HORIZON)\n",
    "    mlflow.log_param(\"num_features\", len(feature_cols))\n",
    "    mlflow.log_param(\"max_depth\", 6)\n",
    "    mlflow.log_param(\"learning_rate\", 0.1)\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Flatten inputs\n",
    "    X_train_flat = X_train_scaled.reshape(len(X_train_scaled), -1)\n",
    "    X_test_flat = X_test_scaled.reshape(len(X_test_scaled), -1)\n",
    "\n",
    "    # Train XGBoost\n",
    "    print(\"Training XGBoost for direction...\")\n",
    "    xgb_clf = XGBClassifier(\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=RANDOM_STATE,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    xgb_clf.fit(X_train_flat, y_direction_train)\n",
    "    y_direction_pred_xgb = xgb_clf.predict(X_test_flat)\n",
    "    y_direction_pred_proba_xgb = xgb_clf.predict_proba(X_test_flat)[:, 1]\n",
    "\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    # Evaluate\n",
    "    clf_metrics = calculate_classification_metrics(y_direction_test, y_direction_pred_xgb, y_direction_pred_proba_xgb)\n",
    "    trading_metrics = simulate_trading(y_direction_test, y_direction_pred_xgb, y_return_test)\n",
    "\n",
    "    # Log to MLflow\n",
    "    for key, val in {**clf_metrics, **trading_metrics}.items():\n",
    "        if key != 'trades':\n",
    "            mlflow.log_metric(key, val)\n",
    "    mlflow.log_metric(\"train_time_seconds\", train_time)\n",
    "\n",
    "    # Save for ensemble\n",
    "    xgb_accuracy = clf_metrics['accuracy']\n",
    "    xgb_sharpe = trading_metrics['sharpe_ratio']\n",
    "\n",
    "    # Dummy reg_metrics for print function\n",
    "    reg_metrics = {'mae': 0, 'rmse': 0, 'r2': 0, 'mape': 0}\n",
    "    print_evaluation_summary(\"XGBoost\", reg_metrics, clf_metrics, trading_metrics)\n",
    "    print(f\"Training time: {train_time:.2f}s\")\n",
    "\n",
    "print(\"XGBoost complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Ensemble: Linear + XGBoost (70-30 weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Ensemble (Linear + XGBoost)...\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Results for Ensemble (Linear 70% + XGBoost 30%)\n",
      "======================================================================\n",
      "\n",
      "[REGRESSION] Return Prediction:\n",
      "  MAE:   0.000%\n",
      "  RMSE:  0.000%\n",
      "  RÂ²:    0.0000\n",
      "  MAPE:  0.00%\n",
      "\n",
      "[CLASSIFICATION] Direction Prediction:\n",
      "  Accuracy:  66.52%\n",
      "  Precision: 69.16%\n",
      "  Recall:    63.59%\n",
      "  F1-Score:  66.26%\n",
      "  ROC-AUC:   0.7248\n",
      "\n",
      "[TRADING SIMULATION]:\n",
      "  Initial Capital:   â‚¹2,727,000.00 (2727 trades Ã— â‚¹1,000)\n",
      "  Final Capital:     â‚¹2,775,286.98\n",
      "  Total Return:      1.77%\n",
      "  Number of Trades:  2727\n",
      "  Win Rate:          67.25%\n",
      "  Avg Return/Trade:  1.771%\n",
      "  Sharpe Ratio:      0.4161\n",
      "======================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PHASE 1-3 RESULTS SUMMARY\n",
      "================================================================================\n",
      "Baseline (04a - 32 features, no class weight):  58.81% accuracy, 0.2095 Sharpe\n",
      "Phase 1 (47 features, class weight):            63.47% accuracy, 0.3227 Sharpe\n",
      "Phase 2 (XGBoost only):                          70.08% accuracy, 0.4992 Sharpe\n",
      "Phase 3 (Ensemble):                              66.52% accuracy, 0.4161 Sharpe\n",
      "\n",
      "âœ… GOAL STATUS:\n",
      "   ðŸŽ¯ SUCCESS! Accuracy 66.52% exceeds 60% target\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Weighted ensemble: Linear (70%) + XGBoost (30%)\n",
    "print(\"\\nRunning Ensemble (Linear + XGBoost)...\\n\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Ensemble_Linear70_XGB30_47features\"):\n",
    "    mlflow.log_param(\"model_type\", \"Ensemble_Linear_XGBoost\")\n",
    "    mlflow.log_param(\"window_size\", WINDOW_SIZE)\n",
    "    mlflow.log_param(\"horizon\", HORIZON)\n",
    "    mlflow.log_param(\"num_features\", len(feature_cols))\n",
    "    mlflow.log_param(\"linear_weight\", 0.7)\n",
    "    mlflow.log_param(\"xgboost_weight\", 0.3)\n",
    "\n",
    "    # Weighted ensemble probabilities\n",
    "    alpha = 0.7  # Linear weight\n",
    "    beta = 0.3   # XGBoost weight\n",
    "    y_ensemble_proba = alpha * y_direction_pred_proba_linear + beta * y_direction_pred_proba_xgb\n",
    "    y_direction_pred_ensemble = (y_ensemble_proba > 0.5).astype(int)\n",
    "\n",
    "    # Evaluate\n",
    "    clf_metrics = calculate_classification_metrics(y_direction_test, y_direction_pred_ensemble, y_ensemble_proba)\n",
    "    trading_metrics = simulate_trading(y_direction_test, y_direction_pred_ensemble, y_return_test)\n",
    "\n",
    "    # Log to MLflow\n",
    "    for key, val in {**clf_metrics, **trading_metrics}.items():\n",
    "        if key != 'trades':\n",
    "            mlflow.log_metric(key, val)\n",
    "\n",
    "    # Dummy reg_metrics\n",
    "    reg_metrics = {'mae': 0, 'rmse': 0, 'r2': 0, 'mape': 0}\n",
    "    print_evaluation_summary(\"Ensemble (Linear 70% + XGBoost 30%)\", reg_metrics, clf_metrics, trading_metrics)\n",
    "\n",
    "    ensemble_accuracy = clf_metrics['accuracy']\n",
    "    ensemble_sharpe = trading_metrics['sharpe_ratio']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 1-3 RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Baseline (04a - 32 features, no class weight):  58.81% accuracy, 0.2095 Sharpe\")\n",
    "print(f\"Phase 1 (47 features, class weight):            {linear_accuracy*100:.2f}% accuracy, {linear_sharpe:.4f} Sharpe\")\n",
    "print(f\"Phase 2 (XGBoost only):                          {xgb_accuracy*100:.2f}% accuracy, {xgb_sharpe:.4f} Sharpe\")\n",
    "print(f\"Phase 3 (Ensemble):                              {ensemble_accuracy*100:.2f}% accuracy, {ensemble_sharpe:.4f} Sharpe\")\n",
    "\n",
    "print(\"\\nâœ… GOAL STATUS:\")\n",
    "if ensemble_accuracy > 0.60:\n",
    "    print(f\"   ðŸŽ¯ SUCCESS! Accuracy {ensemble_accuracy*100:.2f}% exceeds 60% target\")\n",
    "elif linear_accuracy > 0.60:\n",
    "    print(f\"   ðŸŽ¯ SUCCESS! Linear model {linear_accuracy*100:.2f}% exceeds 60% target\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  Not yet at 60% target. Consider Phase 4 (per-stock models)\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Final Comparison with Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison: Baseline vs New Approach\n",
      "====================================================================================================\n",
      "                             Model  Accuracy       F1   Sharpe  Total Return %  Win Rate  Train Time (s)\n",
      "                XGBoost_47features  0.700767 0.697125 0.499166        2.072122  0.708102      109.938113\n",
      "Ensemble_Linear70_XGB30_47features  0.665214 0.662568 0.416094        1.770700  0.672534             NaN\n",
      "   Linear_ClassWeighted_47features  0.634716 0.631375 0.322729        1.427966  0.639338      213.824207\n",
      "                     Linear_Models  0.588132 0.608020 0.209492        0.942082  0.585561      166.927659\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“Š IMPROVEMENT SUMMARY:\n",
      "   Best Model: XGBoost_47features\n",
      "   Accuracy: 58.81% â†’ 70.08% (+11.26%)\n",
      "   Sharpe: 0.2095 â†’ 0.4992 (+138.3%)\n",
      "\n",
      "   ðŸŽ‰ SUCCESS! Exceeded 60% accuracy target!\n"
     ]
    }
   ],
   "source": [
    "# Query all runs from experiment\n",
    "experiment = mlflow.get_experiment_by_name(\"stock-return-prediction-multihorizon\")\n",
    "runs_df = mlflow.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\"metrics.sharpe_ratio DESC\"]\n",
    ")\n",
    "\n",
    "# Filter to show only our new runs + baseline\n",
    "recent_runs = runs_df[runs_df['tags.mlflow.runName'].isin([\n",
    "    'Linear_Models',  # Baseline from 04a\n",
    "    'Linear_ClassWeighted_47features',\n",
    "    'XGBoost_47features',\n",
    "    'Ensemble_Linear70_XGB30_47features'\n",
    "])]\n",
    "\n",
    "print(f\"\\nComparison: Baseline vs New Approach\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Select columns\n",
    "summary_cols = [\n",
    "    'tags.mlflow.runName',\n",
    "    'metrics.accuracy',\n",
    "    'metrics.f1',\n",
    "    'metrics.sharpe_ratio',\n",
    "    'metrics.total_return_pct',\n",
    "    'metrics.win_rate',\n",
    "    'metrics.train_time_seconds'\n",
    "]\n",
    "\n",
    "summary_df = recent_runs[summary_cols].copy()\n",
    "summary_df.columns = ['Model', 'Accuracy', 'F1', 'Sharpe', 'Total Return %', 'Win Rate', 'Train Time (s)']\n",
    "summary_df = summary_df.sort_values('Sharpe', ascending=False)\n",
    "\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Calculate improvements\n",
    "baseline_row = summary_df[summary_df['Model'] == 'Linear_Models']\n",
    "best_row = summary_df.iloc[0]\n",
    "\n",
    "if len(baseline_row) > 0:\n",
    "    baseline_acc = baseline_row['Accuracy'].values[0]\n",
    "    baseline_sharpe = baseline_row['Sharpe'].values[0]\n",
    "    best_acc = best_row['Accuracy']\n",
    "    best_sharpe = best_row['Sharpe']\n",
    "\n",
    "    acc_improvement = (best_acc - baseline_acc) * 100\n",
    "    sharpe_improvement = ((best_sharpe - baseline_sharpe) / baseline_sharpe) * 100\n",
    "\n",
    "    print(f\"\\nðŸ“Š IMPROVEMENT SUMMARY:\")\n",
    "    print(f\"   Best Model: {best_row['Model']}\")\n",
    "    print(f\"   Accuracy: {baseline_acc*100:.2f}% â†’ {best_acc*100:.2f}% (+{acc_improvement:.2f}%)\")\n",
    "    print(f\"   Sharpe: {baseline_sharpe:.4f} â†’ {best_sharpe:.4f} (+{sharpe_improvement:.1f}%)\")\n",
    "\n",
    "    if best_acc > 0.60:\n",
    "        print(f\"\\n   ðŸŽ‰ SUCCESS! Exceeded 60% accuracy target!\")\n",
    "    else:\n",
    "        gap = (0.60 - best_acc) * 100\n",
    "        print(f\"\\n   âš ï¸  Still {gap:.2f}% away from 60% target\")\n",
    "        print(f\"   ðŸ’¡ Next step: Implement Phase 4 (per-stock models)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Save Best Model for Production Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved to: models/xgboost_stock_direction_predictor.pkl\n",
      "âœ… Scaler saved to: models/feature_scaler.pkl\n",
      "\n",
      "Model info:\n",
      "  - Type: XGBoost Classifier\n",
      "  - Accuracy: 70.08%\n",
      "  - Precision: 73.10%\n",
      "  - Sharpe Ratio: 0.4992\n",
      "  - Features: 47 (60-day window)\n",
      "  - Horizon: 7-day prediction\n",
      "\n",
      "ðŸ’¡ Use these files in notebook 10 for production filtering\n"
     ]
    }
   ],
   "source": [
    "# Save the best model (XGBoost) and scaler for production\n",
    "import pickle\n",
    "\n",
    "MODEL_SAVE_PATH = MODELS_DIR / \"xgboost_stock_direction_predictor.pkl\"\n",
    "SCALER_SAVE_PATH = MODELS_DIR / \"feature_scaler.pkl\"\n",
    "\n",
    "# Save XGBoost model\n",
    "with open(MODEL_SAVE_PATH, 'wb') as f:\n",
    "    pickle.dump(xgb_clf, f)\n",
    "\n",
    "# Save scaler\n",
    "with open(SCALER_SAVE_PATH, 'wb') as f:\n",
    "    pickle.dump(scaler_X, f)\n",
    "\n",
    "print(f\"âœ… Model saved to: {MODEL_SAVE_PATH}\")\n",
    "print(f\"âœ… Scaler saved to: {SCALER_SAVE_PATH}\")\n",
    "print(f\"\\nModel info:\")\n",
    "print(f\"  - Type: XGBoost Classifier\")\n",
    "print(f\"  - Accuracy: 70.08%\")\n",
    "print(f\"  - Precision: 73.10%\")\n",
    "print(f\"  - Sharpe Ratio: 0.4992\")\n",
    "print(f\"  - Features: 47 (60-day window)\")\n",
    "print(f\"  - Horizon: 7-day prediction\")\n",
    "print(f\"\\nðŸ’¡ Use these files in notebook 10 for production filtering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loading test successful!\n",
      "   Sample prediction: 1 (UP)\n",
      "   Probabilities: [DOWN: 34.44%, UP: 65.56%]\n"
     ]
    }
   ],
   "source": [
    "# Test loading the saved model\n",
    "with open(MODEL_SAVE_PATH, 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "with open(SCALER_SAVE_PATH, 'rb') as f:\n",
    "    loaded_scaler = pickle.load(f)\n",
    "\n",
    "# Quick test on one sample\n",
    "test_sample = X_test_flat[:1]\n",
    "pred = loaded_model.predict(test_sample)\n",
    "pred_proba = loaded_model.predict_proba(test_sample)\n",
    "\n",
    "print(\"âœ… Model loading test successful!\")\n",
    "print(f\"   Sample prediction: {pred[0]} ({'UP' if pred[0] == 1 else 'DOWN'})\")\n",
    "print(f\"   Probabilities: [DOWN: {pred_proba[0][0]:.2%}, UP: {pred_proba[0][1]:.2%}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### What We Built\n",
    "1. **Advanced Feature Engineering**: Added 15 new technical features (47 total)\n",
    "2. **Best Model**: XGBoost classifier with 70.08% accuracy (+11.26% over baseline)\n",
    "3. **Saved for Production**: Model and scaler ready for notebook 10\n",
    "\n",
    "### Performance Metrics\n",
    "- **Accuracy**: 70.08% (target was >60%)\n",
    "- **Precision**: 73.10% (when predicts UP, correct 73% of time)\n",
    "- **Win Rate**: 70.81% in trading simulation\n",
    "- **Sharpe Ratio**: 0.4992 (+138% over baseline)\n",
    "\n",
    "### Next Steps\n",
    "1. Open **notebook 10** ([10_production_ml_filter.ipynb](10_production_ml_filter.ipynb))\n",
    "2. Provide LLM-recommended stock symbols as input\n",
    "3. Get ML-filtered BUY recommendations\n",
    "\n",
    "### Production Usage Example\n",
    "```python\n",
    "# In notebook 10\n",
    "llm_stocks = ['RELIANCE', 'TCS', 'INFY', 'HDFCBANK', 'ICICIBANK']\n",
    "filtered = filter_llm_recommendations(llm_stocks, model, scaler)\n",
    "buy_list = filtered[filtered['recommendation'] == 'BUY']\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock-curator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
