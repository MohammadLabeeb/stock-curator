{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "075829c3",
   "metadata": {},
   "source": [
    "# Notebook 2: Stock Data Collection & Model Training with Upstox API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff019d15",
   "metadata": {},
   "source": [
    "## 1. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f68b2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 13:43:41.978276: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-02 13:43:43.049739: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-02 13:43:50.573432: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n",
      "TensorFlow version: 2.20.0\n",
      "Pandas version: 2.3.3\n",
      "NumPy version: 2.2.6\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# API and HTTP requests\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning - Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "\n",
    "# Machine Learning - Models\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Deep Learning (TensorFlow/Keras)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Bidirectional, GRU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Time series specific\n",
    "from prophet import Prophet  # Facebook Prophet for comparison\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cae24bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration\n",
    "UPSTOX_ACCESS_TOKEN = os.getenv(\"UPSTOX_ACCESS_TOKEN\")\n",
    "BASE_URL = \"https://api.upstox.com/v3/historical-candle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b12f34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching historical data for Reliance Industries...\n",
      "\n",
      "SUCCESS! Got stock data!\n",
      "\n",
      "Received 21 days of data\n",
      "\n",
      "Sample data (last 3 days):\n",
      "Date         Open       High       Low        Close      Volume         \n",
      "----------------------------------------------------------------------\n",
      "2025-10-06   1360.00    1377.40    1359.00    1375.00    12,396,580     \n",
      "2025-10-03   1363.20    1371.60    1356.90    1363.40    12,842,347     \n",
      "2025-10-01   1367.00    1378.60    1362.70    1368.70    12,045,916     \n"
     ]
    }
   ],
   "source": [
    "# Simple tests to verify Upstox API access\n",
    "\n",
    "# Fetch historical stock data\n",
    "\n",
    "headers = {\n",
    "    'Accept': 'application/json',\n",
    "    'Authorization': f'Bearer {UPSTOX_ACCESS_TOKEN}'\n",
    "    }\n",
    "\n",
    "print(\"Fetching historical data for Reliance Industries...\\n\")\n",
    "\n",
    "# Reliance Industries ISIN: INE002A01018\n",
    "stock_url = 'https://api.upstox.com/v3/historical-candle/NSE_EQ%7CINE002A01018/days/1/2025-11-01/2025-10-01'\n",
    "\n",
    "response = requests.get(stock_url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"SUCCESS! Got stock data!\")\n",
    "    data = response.json()\n",
    "    \n",
    "    if data['status'] == 'success':\n",
    "        candles = data['data']['candles']\n",
    "        print(f\"\\nReceived {len(candles)} days of data\")\n",
    "        print(f\"\\nSample data (last 3 days):\")\n",
    "        print(f\"{'Date':<12} {'Open':<10} {'High':<10} {'Low':<10} {'Close':<10} {'Volume':<15}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for candle in candles[-3:]:\n",
    "            date, open_p, high, low, close, volume, _ = candle\n",
    "            print(f\"{date[:10]:<12} {open_p:<10.2f} {high:<10.2f} {low:<10.2f} {close:<10.2f} {volume:<15,}\")\n",
    "else:\n",
    "    print(f\"ERROR: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ba411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NIFTY 100 Stock List (as of November 2025)\n",
    "# This represents the top 100 companies by market capitalization on NSE\n",
    "\n",
    "nifty_100_stocks = [\n",
    "    # NIFTY 50 components (Top 50)\n",
    "    \"RELIANCE\",        # Reliance Industries Ltd\n",
    "    \"HDFCBANK\",        # HDFC Bank Ltd\n",
    "    \"BHARTIARTL\",      # Bharti Airtel Ltd\n",
    "    \"TCS\",             # Tata Consultancy Services Ltd\n",
    "    \"ICICIBANK\",       # ICICI Bank Ltd\n",
    "    \"SBIN\",            # State Bank of India\n",
    "    \"BAJFINANCE\",      # Bajaj Finance Ltd\n",
    "    \"INFY\",            # Infosys Ltd\n",
    "    \"HINDUNILVR\",      # Hindustan Unilever Ltd\n",
    "    \"LT\",              # Larsen & Toubro Ltd\n",
    "    \"ITC\",             # ITC Ltd\n",
    "    \"MARUTI\",          # Maruti Suzuki India Ltd\n",
    "    \"M&M\",             # Mahindra & Mahindra Ltd\n",
    "    \"KOTAKBANK\",       # Kotak Mahindra Bank Ltd\n",
    "    \"HCLTECH\",         # HCL Technologies Ltd\n",
    "    \"SUNPHARMA\",       # Sun Pharmaceutical Industries Ltd\n",
    "    \"AXISBANK\",        # Axis Bank Ltd\n",
    "    \"ULTRACEMCO\",      # UltraTech Cement Ltd\n",
    "    \"ZOMATO\",          # Zomato Ltd\n",
    "    \"BAJAJFINSV\",      # Bajaj Finserv Ltd\n",
    "    \"NTPC\",            # NTPC Ltd\n",
    "    \"LICI\",            # Life Insurance Corporation of India\n",
    "    \"TITAN\",           # Titan Company Ltd\n",
    "    \"ASIANPAINT\",      # Asian Paints Ltd\n",
    "    \"TATAMOTORS\",      # Tata Motors Ltd\n",
    "    \"ADANIENT\",        # Adani Enterprises Ltd\n",
    "    \"WIPRO\",           # Wipro Ltd\n",
    "    \"ONGC\",            # Oil and Natural Gas Corporation Ltd\n",
    "    \"HDFCLIFE\",        # HDFC Life Insurance Company Ltd\n",
    "    \"JSWSTEEL\",        # JSW Steel Ltd\n",
    "    \"POWERGRID\",       # Power Grid Corporation of India Ltd\n",
    "    \"ADANIPORTS\",      # Adani Ports and Special Economic Zone Ltd\n",
    "    \"COALINDIA\",       # Coal India Ltd\n",
    "    \"SBILIFE\",         # SBI Life Insurance Company Ltd\n",
    "    \"TECHM\",           # Tech Mahindra Ltd\n",
    "    \"TATASTEEL\",       # Tata Steel Ltd\n",
    "    \"INDUSINDBK\",      # IndusInd Bank Ltd\n",
    "    \"HINDALCO\",        # Hindalco Industries Ltd\n",
    "    \"DIVISLAB\",        # Divi's Laboratories Ltd\n",
    "    \"NESTLEIND\",       # Nestle India Ltd\n",
    "    \"BRITANNIA\",       # Britannia Industries Ltd\n",
    "    \"GRASIM\",          # Grasim Industries Ltd\n",
    "    \"EICHERMOT\",       # Eicher Motors Ltd\n",
    "    \"TRENT\",           # Trent Ltd\n",
    "    \"BAJAJ-AUTO\",      # Bajaj Auto Ltd\n",
    "    \"TATACONSUM\",      # Tata Consumer Products Ltd\n",
    "    \"CIPLA\",           # Cipla Ltd\n",
    "    \"BPCL\",            # Bharat Petroleum Corporation Ltd\n",
    "    \"APOLLOHOSP\",      # Apollo Hospitals Enterprise Ltd\n",
    "    \"DRREDDY\",         # Dr. Reddy's Laboratories Ltd\n",
    "    \n",
    "    # NIFTY Next 50 components (Next 50 largest)\n",
    "    \"ADANIGREEN\",      # Adani Green Energy Ltd\n",
    "    \"SIEMENS\",         # Siemens Ltd\n",
    "    \"DLF\",             # DLF Ltd\n",
    "    \"PIDILITIND\",      # Pidilite Industries Ltd\n",
    "    \"JIOFIN\",          # Jio Financial Services Ltd\n",
    "    \"GAIL\",            # GAIL (India) Ltd\n",
    "    \"HAL\",             # Hindustan Aeronautics Ltd\n",
    "    \"GODREJCP\",        # Godrej Consumer Products Ltd\n",
    "    \"ADANIPOWER\",      # Adani Power Ltd\n",
    "    \"IOC\",             # Indian Oil Corporation Ltd\n",
    "    \"ABB\",             # ABB India Ltd\n",
    "    \"VEDL\",            # Vedanta Ltd\n",
    "    \"ICICIPRULI\",      # ICICI Prudential Life Insurance Company Ltd\n",
    "    \"SHREECEM\",        # Shree Cement Ltd\n",
    "    \"IRFC\",            # Indian Railway Finance Corporation Ltd\n",
    "    \"CHOLAFIN\",        # Cholamandalam Investment and Finance Company Ltd\n",
    "    \"AMBUJACEM\",       # Ambuja Cements Ltd\n",
    "    \"SRF\",             # SRF Ltd\n",
    "    \"BOSCHLTD\",        # Bosch Ltd\n",
    "    \"MCDOWELL-N\",      # United Spirits Ltd\n",
    "    \"DABUR\",           # Dabur India Ltd\n",
    "    \"HAVELLS\",         # Havells India Ltd\n",
    "    \"INDIGO\",          # InterGlobe Aviation Ltd\n",
    "    \"BERGEPAINT\",      # Berger Paints India Ltd\n",
    "    \"BEL\",             # Bharat Electronics Ltd\n",
    "    \"TORNTPHARM\",      # Torrent Pharmaceuticals Ltd\n",
    "    \"MOTHERSON\",       # Samvardhana Motherson International Ltd\n",
    "    \"LUPIN\",           # Lupin Ltd\n",
    "    \"TATAPOWER\",       # Tata Power Company Ltd\n",
    "    \"NAUKRI\",          # Info Edge (India) Ltd\n",
    "    \"MARICO\",          # Marico Ltd\n",
    "    \"CANBK\",           # Canara Bank\n",
    "    \"BAJAJHLDNG\",      # Bajaj Holdings & Investment Ltd\n",
    "    \"BANKBARODA\",      # Bank of Baroda\n",
    "    \"UNIONBANK\",       # Union Bank of India\n",
    "    \"PNB\",             # Punjab National Bank\n",
    "    \"PGHH\",            # Procter & Gamble Hygiene and Health Care Ltd\n",
    "    \"COLPAL\",          # Colgate-Palmolive (India) Ltd\n",
    "    \"SBICARD\",         # SBI Cards and Payment Services Ltd\n",
    "    \"YESBANK\",         # Yes Bank Ltd\n",
    "    \"IDEA\",            # Vodafone Idea Ltd\n",
    "    \"HINDZINC\",        # Hindustan Zinc Ltd\n",
    "    \"PAGEIND\",         # Page Industries Ltd\n",
    "    \"MAXHEALTH\",       # Max Healthcare Institute Ltd\n",
    "    \"ICICIGI\",         # ICICI Lombard General Insurance Company Ltd\n",
    "    \"IRCTC\",           # Indian Railway Catering and Tourism Corporation Ltd\n",
    "    \"ABBOTINDIA\",      # Abbott India Ltd\n",
    "    \"GLAXO\",           # GlaxoSmithKline Pharmaceuticals Ltd\n",
    "    \"DMART\",           # Avenue Supermarts Ltd\n",
    "    \"ALKEM\",           # Alkem Laboratories Ltd\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d845f6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Configuration complete!\n",
      "Data collection period: 2023-11-03 to 2025-11-02\n"
     ]
    }
   ],
   "source": [
    "# Date Range Configuration\n",
    "END_DATE = datetime.now().strftime('%Y-%m-%d')\n",
    "START_DATE = (datetime.now() - timedelta(days=730)).strftime('%Y-%m-%d')  # 2 years\n",
    "\n",
    "# Model Configuration\n",
    "SEQUENCE_LENGTH = 60  # Number of days to look back\n",
    "PREDICTION_HORIZON = 7  # Number of days to predict ahead\n",
    "TRAIN_SPLIT = 0.7\n",
    "VAL_SPLIT = 0.15\n",
    "TEST_SPLIT = 0.15\n",
    "\n",
    "# Directory Structure\n",
    "DATA_DIR = \"data\"\n",
    "RAW_DATA_DIR = f\"{DATA_DIR}/raw\"\n",
    "PROCESSED_DATA_DIR = f\"{DATA_DIR}/processed\"\n",
    "MODELS_DIR = \"models\"\n",
    "STOCK_DATA_DIR = f\"{PROCESSED_DATA_DIR}/stock_data\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [RAW_DATA_DIR, PROCESSED_DATA_DIR, MODELS_DIR, STOCK_DATA_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "print(\" Configuration complete!\")\n",
    "print(f\"Data collection period: {START_DATE} to {END_DATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9y2heovcj4f",
   "metadata": {},
   "source": [
    "## 2. Load Stock Lookup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bnjnoxenv7v",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded stock lookup data\n",
      "Total stocks in lookup: 2252\n",
      "\n",
      "Sample stock data (RELIANCE):\n",
      "{\n",
      "  \"segment\": \"NSE_EQ\",\n",
      "  \"name\": \"RELIANCE INDUSTRIES LTD\",\n",
      "  \"exchange\": \"NSE\",\n",
      "  \"isin\": \"INE002A01018\",\n",
      "  \"instrument_type\": \"EQ\",\n",
      "  \"instrument_key\": \"NSE_EQ|INE002A01018\",\n",
      "  \"lot_size\": 1,\n",
      "  \"freeze_quantity\": 100000.0,\n",
      "  \"exchange_token\": \"2885\",\n",
      "  \"tick_size\": 10.0,\n",
      "  \"trading_symbol\": \"RELIANCE\",\n",
      "  \"short_name\": \"Reliance\",\n",
      "  \"qty_multiplier\": 1.0,\n",
      "  \"mtf_enabled\": true,\n",
      "  \"mtf_bracket\": 26.5,\n",
      "  \"security_type\": \"NORMAL\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load stock lookup data\n",
    "STOCK_LOOKUP_PATH = os.path.join(PROCESSED_DATA_DIR, 'stock_lookup.json')\n",
    "\n",
    "with open(STOCK_LOOKUP_PATH, 'r') as f:\n",
    "    stock_lookup = json.load(f)\n",
    "\n",
    "print(f\"Loaded stock lookup data\")\n",
    "print(f\"Total stocks in lookup: {len(stock_lookup['by_symbol'])}\")\n",
    "print(f\"\\nSample stock data (RELIANCE):\")\n",
    "if 'RELIANCE' in stock_lookup['by_symbol']:\n",
    "    reliance_data = stock_lookup['by_symbol']['RELIANCE']\n",
    "    print(json.dumps(reliance_data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pczgnjh1ey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully mapped 98/100 NIFTY 100 stocks\n",
      "\n",
      "Successfully mapped stocks: 98\n",
      "\n",
      " Missing stocks (2):\n",
      "  - ZOMATO\n",
      "  - MCDOWELL-N\n",
      "\n",
      " Sample mappings:\n",
      "RELIANCE        -> INE002A01018    (RELIANCE INDUSTRIES LTD)\n",
      "HDFCBANK        -> INE040A01034    (HDFC BANK LTD)\n",
      "BHARTIARTL      -> INE397D01024    (BHARTI AIRTEL LIMITED)\n",
      "TCS             -> INE467B01029    (TATA CONSULTANCY SERV LT)\n",
      "ICICIBANK       -> INE090A01021    (ICICI BANK LTD.)\n"
     ]
    }
   ],
   "source": [
    "# Map NIFTY 100 symbols to ISIN codes\n",
    "nifty_100_mapping = {}\n",
    "missing_stocks = []\n",
    "\n",
    "for symbol in nifty_100_stocks:\n",
    "    if symbol in stock_lookup['by_symbol']:\n",
    "        stock_info = stock_lookup['by_symbol'][symbol]\n",
    "        nifty_100_mapping[symbol] = {\n",
    "            'isin': stock_info['isin'],\n",
    "            'name': stock_info['name'],\n",
    "            'trading_symbol': stock_info['trading_symbol'],\n",
    "            'instrument_key': stock_info['instrument_key']\n",
    "        }\n",
    "    else:\n",
    "        missing_stocks.append(symbol)\n",
    "\n",
    "print(f\"Successfully mapped {len(nifty_100_mapping)}/{len(nifty_100_stocks)} NIFTY 100 stocks\")\n",
    "print(f\"\\nSuccessfully mapped stocks: {len(nifty_100_mapping)}\")\n",
    "\n",
    "if missing_stocks:\n",
    "    print(f\"\\n Missing stocks ({len(missing_stocks)}):\")\n",
    "    for stock in missing_stocks:\n",
    "        print(f\"  - {stock}\")\n",
    "else:\n",
    "    print(\"\\n All NIFTY 100 stocks found in lookup!\")\n",
    "\n",
    "# Display sample mappings\n",
    "print(\"\\n Sample mappings:\")\n",
    "for i, (symbol, info) in enumerate(list(nifty_100_mapping.items())[:5]):\n",
    "    print(f\"{symbol:15} -> {info['isin']:15} ({info['name']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dw538snuna",
   "metadata": {},
   "source": [
    "## 3. API Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0hrho5zpja3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " HTTP session created with retry logic\n"
     ]
    }
   ],
   "source": [
    "def create_session_with_retries(retries=3, backoff_factor=0.3):\n",
    "    \"\"\"\n",
    "    Create a requests session with retry logic\n",
    "    \n",
    "    Args:\n",
    "        retries: Number of retry attempts\n",
    "        backoff_factor: Backoff factor for retries\n",
    "    \n",
    "    Returns:\n",
    "        requests.Session object with retry configuration\n",
    "    \"\"\"\n",
    "    session = requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=(500, 502, 504),\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "# Create global session\n",
    "session = create_session_with_retries()\n",
    "print(\" HTTP session created with retry logic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "qcz3sgn33xa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fetch_historical_data() function defined\n"
     ]
    }
   ],
   "source": [
    "def fetch_historical_data(isin: str, \n",
    "                          interval: str = 'days',\n",
    "                          candle_interval: str = '1',\n",
    "                          start_date: str = None,\n",
    "                          end_date: str = None,\n",
    "                          access_token: str = None) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Fetch historical stock data from Upstox API\n",
    "    \n",
    "    Args:\n",
    "        isin: ISIN code of the stock (e.g., 'INE002A01018')\n",
    "        interval: Time interval ('days', 'weeks', 'months')\n",
    "        candle_interval: Candle interval ('1', '30', '60', etc.)\n",
    "        start_date: Start date in YYYY-MM-DD format\n",
    "        end_date: End date in YYYY-MM-DD format\n",
    "        access_token: Upstox API access token\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: Date, Open, High, Low, Close, Volume, OI\n",
    "        None if request fails\n",
    "    \"\"\"\n",
    "    if access_token is None:\n",
    "        access_token = UPSTOX_ACCESS_TOKEN\n",
    "    \n",
    "    if not access_token:\n",
    "        print(\" Error: UPSTOX_ACCESS_TOKEN not set\")\n",
    "        return None\n",
    "    \n",
    "    if start_date is None:\n",
    "        start_date = START_DATE\n",
    "    if end_date is None:\n",
    "        end_date = END_DATE\n",
    "    \n",
    "    # Build URL: /v3/historical-candle/{instrument_key}/{interval}/{candle_interval}/{end_date}/{start_date}\n",
    "    instrument_key = f\"NSE_EQ%7C{isin}\"  # URL encode the pipe character\n",
    "    url = f\"https://api.upstox.com/v3/historical-candle/{instrument_key}/{interval}/{candle_interval}/{end_date}/{start_date}\"\n",
    "    \n",
    "    headers = {\n",
    "        'Accept': 'application/json',\n",
    "        'Authorization': f'Bearer {access_token}'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = session.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            if data.get('status') == 'success' and 'data' in data:\n",
    "                candles = data['data'].get('candles', [])\n",
    "                \n",
    "                if not candles:\n",
    "                    print(f\"  No data returned for ISIN: {isin}\")\n",
    "                    return None\n",
    "                \n",
    "                # Convert to DataFrame\n",
    "                df = pd.DataFrame(candles, columns=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'OI'])\n",
    "                \n",
    "                # Convert date to datetime\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "                \n",
    "                # Sort by date ascending\n",
    "                df = df.sort_values('Date').reset_index(drop=True)\n",
    "                \n",
    "                return df\n",
    "            else:\n",
    "                print(f\" API returned error for {isin}: {data.get('message', 'Unknown error')}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\" HTTP {response.status_code} for {isin}: {response.text[:200]}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\" Exception while fetching {isin}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\" fetch_historical_data() function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vs1ckj121co",
   "metadata": {},
   "source": [
    "## 4. Data Processing & Storage Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "z3jfbl2jrs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " add_technical_indicators() function defined\n"
     ]
    }
   ],
   "source": [
    "def add_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add technical indicators to the dataframe\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with OHLCV data\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with additional technical indicators\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Moving Averages\n",
    "    df['SMA_5'] = df['Close'].rolling(window=5).mean()\n",
    "    df['SMA_10'] = df['Close'].rolling(window=10).mean()\n",
    "    df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
    "    \n",
    "    # Exponential Moving Averages\n",
    "    df['EMA_12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    df['EMA_26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    \n",
    "    # MACD\n",
    "    df['MACD'] = df['EMA_12'] - df['EMA_26']\n",
    "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    df['MACD_Hist'] = df['MACD'] - df['MACD_Signal']\n",
    "    \n",
    "    # RSI (Relative Strength Index)\n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    df['BB_Middle'] = df['Close'].rolling(window=20).mean()\n",
    "    bb_std = df['Close'].rolling(window=20).std()\n",
    "    df['BB_Upper'] = df['BB_Middle'] + (bb_std * 2)\n",
    "    df['BB_Lower'] = df['BB_Middle'] - (bb_std * 2)\n",
    "    \n",
    "    # Volume indicators\n",
    "    df['Volume_SMA_20'] = df['Volume'].rolling(window=20).mean()\n",
    "    df['Volume_Ratio'] = df['Volume'] / df['Volume_SMA_20']\n",
    "    \n",
    "    # Price change indicators\n",
    "    df['Daily_Return'] = df['Close'].pct_change()\n",
    "    df['Price_Range'] = df['High'] - df['Low']\n",
    "    df['Price_Change'] = df['Close'] - df['Open']\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\" add_technical_indicators() function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83ykf02v38y",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " save_stock_data() and load_stock_data() functions defined\n"
     ]
    }
   ],
   "source": [
    "def save_stock_data(df: pd.DataFrame, symbol: str, stock_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    Save stock data to CSV file\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with stock data\n",
    "        symbol: Stock symbol (e.g., 'RELIANCE')\n",
    "        stock_name: Full stock name\n",
    "    \n",
    "    Returns:\n",
    "        True if saved successfully, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        filename = f\"{symbol}_historical.csv\"\n",
    "        filepath = os.path.join(STOCK_DATA_DIR, filename)\n",
    "        \n",
    "        # Save to CSV\n",
    "        df.to_csv(filepath, index=False)\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\" Error saving {symbol}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def load_stock_data(symbol: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load stock data from CSV file\n",
    "    \n",
    "    Args:\n",
    "        symbol: Stock symbol (e.g., 'RELIANCE')\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with stock data, or None if file doesn't exist\n",
    "    \"\"\"\n",
    "    try:\n",
    "        filename = f\"{symbol}_historical.csv\"\n",
    "        filepath = os.path.join(STOCK_DATA_DIR, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_csv(filepath)\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            return df\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\" Error loading {symbol}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\" save_stock_data() and load_stock_data() functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9lxcz29vcj",
   "metadata": {},
   "source": [
    "## 5. Collect Stock Data for NIFTY 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4qm63rbaknq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection for 98 NIFTY 100 stocks\n",
      "Date range: 2023-11-03 to 2025-11-02\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c569513e95734dac8f5f97357133f1d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting stock data:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing: RELIANCE (RELIANCE INDUSTRIES LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to RELIANCE_historical.csv\n",
      "\n",
      " Processing: HDFCBANK (HDFC BANK LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to HDFCBANK_historical.csv\n",
      "\n",
      " Processing: BHARTIARTL (BHARTI AIRTEL LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to BHARTIARTL_historical.csv\n",
      "\n",
      " Processing: TCS (TATA CONSULTANCY SERV LT)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to TCS_historical.csv\n",
      "\n",
      " Processing: ICICIBANK (ICICI BANK LTD.)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to ICICIBANK_historical.csv\n",
      "\n",
      " Processing: SBIN (STATE BANK OF INDIA)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to SBIN_historical.csv\n",
      "\n",
      " Processing: BAJFINANCE (BAJAJ FINANCE LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to BAJFINANCE_historical.csv\n",
      "\n",
      " Processing: INFY (INFOSYS LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to INFY_historical.csv\n",
      "\n",
      " Processing: HINDUNILVR (HINDUSTAN UNILEVER LTD.)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to HINDUNILVR_historical.csv\n",
      "\n",
      " Processing: LT (LARSEN & TOUBRO LTD.)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to LT_historical.csv\n",
      "\n",
      " Processing: ITC (ITC LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to ITC_historical.csv\n",
      "\n",
      " Processing: MARUTI (MARUTI SUZUKI INDIA LTD.)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to MARUTI_historical.csv\n",
      "\n",
      " Processing: M&M (MAHINDRA & MAHINDRA LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to M&M_historical.csv\n",
      "\n",
      " Processing: KOTAKBANK (KOTAK MAHINDRA BANK LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to KOTAKBANK_historical.csv\n",
      "\n",
      " Processing: HCLTECH (HCL TECHNOLOGIES LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to HCLTECH_historical.csv\n",
      "\n",
      " Processing: SUNPHARMA (SUN PHARMACEUTICAL IND L)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to SUNPHARMA_historical.csv\n",
      "\n",
      " Processing: AXISBANK (AXIS BANK LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to AXISBANK_historical.csv\n",
      "\n",
      " Processing: ULTRACEMCO (ULTRATECH CEMENT LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to ULTRACEMCO_historical.csv\n",
      "\n",
      " Processing: BAJAJFINSV (BAJAJ FINSERV LTD.)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to BAJAJFINSV_historical.csv\n",
      "\n",
      " Processing: NTPC (NTPC LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to NTPC_historical.csv\n",
      "\n",
      " Processing: LICI (LIFE INSURA CORP OF INDIA)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to LICI_historical.csv\n",
      "\n",
      " Processing: TITAN (TITAN COMPANY LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to TITAN_historical.csv\n",
      "\n",
      " Processing: ASIANPAINT (ASIAN PAINTS LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to ASIANPAINT_historical.csv\n",
      "\n",
      " Processing: TATAMOTORS (TATA MOTORS LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to TATAMOTORS_historical.csv\n",
      "\n",
      " Processing: ADANIENT (ADANI ENTERPRISES LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to ADANIENT_historical.csv\n",
      "\n",
      " Processing: WIPRO (WIPRO LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to WIPRO_historical.csv\n",
      "\n",
      " Processing: ONGC (OIL AND NATURAL GAS CORP.)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to ONGC_historical.csv\n",
      "\n",
      " Processing: HDFCLIFE (HDFC LIFE INS CO LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to HDFCLIFE_historical.csv\n",
      "\n",
      " Processing: JSWSTEEL (JSW STEEL LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to JSWSTEEL_historical.csv\n",
      "\n",
      " Processing: POWERGRID (POWER GRID CORP. LTD.)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to POWERGRID_historical.csv\n",
      "\n",
      " Processing: ADANIPORTS (ADANI PORT & SEZ LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to ADANIPORTS_historical.csv\n",
      "\n",
      " Processing: COALINDIA (COAL INDIA LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to COALINDIA_historical.csv\n",
      "\n",
      " Processing: SBILIFE (SBI LIFE INSURANCE CO LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to SBILIFE_historical.csv\n",
      "\n",
      " Processing: TECHM (TECH MAHINDRA LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to TECHM_historical.csv\n",
      "\n",
      " Processing: TATASTEEL (TATA STEEL LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to TATASTEEL_historical.csv\n",
      "\n",
      " Processing: INDUSINDBK (INDUSIND BANK LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to INDUSINDBK_historical.csv\n",
      "\n",
      " Processing: HINDALCO (HINDALCO  INDUSTRIES  LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to HINDALCO_historical.csv\n",
      "\n",
      " Processing: DIVISLAB (DIVI S LABORATORIES LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to DIVISLAB_historical.csv\n",
      "\n",
      " Processing: NESTLEIND (NESTLE INDIA LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to NESTLEIND_historical.csv\n",
      "\n",
      " Processing: BRITANNIA (BRITANNIA INDUSTRIES LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to BRITANNIA_historical.csv\n",
      "\n",
      " Processing: GRASIM (GRASIM INDUSTRIES LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to GRASIM_historical.csv\n",
      "\n",
      " Processing: EICHERMOT (EICHER MOTORS LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to EICHERMOT_historical.csv\n",
      "\n",
      " Processing: TRENT (TRENT LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to TRENT_historical.csv\n",
      "\n",
      " Processing: BAJAJ-AUTO (BAJAJ AUTO LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to BAJAJ-AUTO_historical.csv\n",
      "\n",
      " Processing: TATACONSUM (TATA CONSUMER PRODUCT LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to TATACONSUM_historical.csv\n",
      "\n",
      " Processing: CIPLA (CIPLA LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to CIPLA_historical.csv\n",
      "\n",
      " Processing: BPCL (BHARAT PETROLEUM CORP  LT)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to BPCL_historical.csv\n",
      "\n",
      " Processing: APOLLOHOSP (APOLLO HOSPITALS ENTER. L)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to APOLLOHOSP_historical.csv\n",
      "\n",
      " Processing: DRREDDY (DR. REDDY S LABORATORIES)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to DRREDDY_historical.csv\n",
      "\n",
      " Processing: ADANIGREEN (ADANI GREEN ENERGY LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to ADANIGREEN_historical.csv\n",
      "\n",
      " Processing: SIEMENS (SIEMENS LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to SIEMENS_historical.csv\n",
      "\n",
      " Processing: DLF (DLF LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to DLF_historical.csv\n",
      "\n",
      " Processing: PIDILITIND (PIDILITE INDUSTRIES LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to PIDILITIND_historical.csv\n",
      "\n",
      " Processing: JIOFIN (JIO FIN SERVICES LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to JIOFIN_historical.csv\n",
      "\n",
      " Processing: GAIL (GAIL (INDIA) LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to GAIL_historical.csv\n",
      "\n",
      " Processing: HAL (HINDUSTAN AERONAUTICS LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to HAL_historical.csv\n",
      "\n",
      " Processing: GODREJCP (GODREJ CONSUMER PRODUCTS)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to GODREJCP_historical.csv\n",
      "\n",
      " Processing: ADANIPOWER (ADANI POWER LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to ADANIPOWER_historical.csv\n",
      "\n",
      " Processing: IOC (INDIAN OIL CORP LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to IOC_historical.csv\n",
      "\n",
      " Processing: ABB (ABB INDIA LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to ABB_historical.csv\n",
      "\n",
      " Processing: VEDL (VEDANTA LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to VEDL_historical.csv\n",
      "\n",
      " Processing: ICICIPRULI (ICICI PRU LIFE INS CO LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to ICICIPRULI_historical.csv\n",
      "\n",
      " Processing: SHREECEM (SHREE CEMENT LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to SHREECEM_historical.csv\n",
      "\n",
      " Processing: IRFC (INDIAN RAILWAY FIN CORP L)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to IRFC_historical.csv\n",
      "\n",
      " Processing: CHOLAFIN (CHOLAMANDALAM IN & FIN CO)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to CHOLAFIN_historical.csv\n",
      "\n",
      " Processing: AMBUJACEM (AMBUJA CEMENTS LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to AMBUJACEM_historical.csv\n",
      "\n",
      " Processing: SRF (SRF LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to SRF_historical.csv\n",
      "\n",
      " Processing: BOSCHLTD (BOSCH LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to BOSCHLTD_historical.csv\n",
      "\n",
      " Processing: DABUR (DABUR INDIA LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to DABUR_historical.csv\n",
      "\n",
      " Processing: HAVELLS (HAVELLS INDIA LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to HAVELLS_historical.csv\n",
      "\n",
      " Processing: INDIGO (INTERGLOBE AVIATION LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to INDIGO_historical.csv\n",
      "\n",
      " Processing: BERGEPAINT (BERGER PAINTS (I) LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to BERGEPAINT_historical.csv\n",
      "\n",
      " Processing: BEL (BHARAT ELECTRONICS LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to BEL_historical.csv\n",
      "\n",
      " Processing: TORNTPHARM (TORRENT PHARMACEUTICALS L)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to TORNTPHARM_historical.csv\n",
      "\n",
      " Processing: MOTHERSON (SAMVRDHNA MTHRSN INTL LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to MOTHERSON_historical.csv\n",
      "\n",
      " Processing: LUPIN (LUPIN LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to LUPIN_historical.csv\n",
      "\n",
      " Processing: TATAPOWER (TATA POWER CO LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to TATAPOWER_historical.csv\n",
      "\n",
      " Processing: NAUKRI (INFO EDGE (I) LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to NAUKRI_historical.csv\n",
      "\n",
      " Processing: MARICO (MARICO LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to MARICO_historical.csv\n",
      "\n",
      " Processing: CANBK (CANARA BANK)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to CANBK_historical.csv\n",
      "\n",
      " Processing: BAJAJHLDNG (BAJAJ HOLDINGS & INVS LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to BAJAJHLDNG_historical.csv\n",
      "\n",
      " Processing: BANKBARODA (BANK OF BARODA)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to BANKBARODA_historical.csv\n",
      "\n",
      " Processing: UNIONBANK (UNION BANK OF INDIA)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to UNIONBANK_historical.csv\n",
      "\n",
      " Processing: PNB (PUNJAB NATIONAL BANK)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to PNB_historical.csv\n",
      "\n",
      " Processing: PGHH (P&G HYGIENE & HEALTH CARE)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to PGHH_historical.csv\n",
      "\n",
      " Processing: COLPAL (COLGATE PALMOLIVE LTD.)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to COLPAL_historical.csv\n",
      "\n",
      " Processing: SBICARD (SBI CARDS & PAY SER LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to SBICARD_historical.csv\n",
      "\n",
      " Processing: YESBANK (YES BANK LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to YESBANK_historical.csv\n",
      "\n",
      " Processing: IDEA (VODAFONE IDEA LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to IDEA_historical.csv\n",
      "\n",
      " Processing: HINDZINC (HINDUSTAN ZINC LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to HINDZINC_historical.csv\n",
      "\n",
      " Processing: PAGEIND (PAGE INDUSTRIES LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to PAGEIND_historical.csv\n",
      "\n",
      " Processing: MAXHEALTH (MAX HEALTHCARE INS LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to MAXHEALTH_historical.csv\n",
      "\n",
      " Processing: ICICIGI (ICICI LOMBARD GIC LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to ICICIGI_historical.csv\n",
      "\n",
      " Processing: IRCTC (INDIAN RAIL TOUR CORP LTD)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to IRCTC_historical.csv\n",
      "\n",
      " Processing: ABBOTINDIA (ABBOTT INDIA LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to ABBOTINDIA_historical.csv\n",
      "\n",
      " Processing: GLAXO (GLAXOSMITHKLINE PHARMA LT)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to GLAXO_historical.csv\n",
      "\n",
      " Processing: DMART (AVENUE SUPERMARTS LIMITED)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to DMART_historical.csv\n",
      "\n",
      " Processing: ALKEM (ALKEM LABORATORIES LTD.)\n",
      "   Fetched 496 records\n",
      "   Added technical indicators\n",
      "   Saved to ALKEM_historical.csv\n",
      "\n",
      "================================================================================\n",
      "DATA COLLECTION COMPLETE!\n",
      "================================================================================\n",
      " Successful: 98 stocks\n",
      " Failed: 0 stocks\n",
      " Total records collected: 48,608\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "# Track collection statistics\n",
    "collection_stats = {\n",
    "    'successful': [],\n",
    "    'failed': [],\n",
    "    'skipped': [],\n",
    "    'total_records': 0\n",
    "}\n",
    "\n",
    "# Main data collection loop\n",
    "print(f\"Starting data collection for {len(nifty_100_mapping)} NIFTY 100 stocks\")\n",
    "print(f\"Date range: {START_DATE} to {END_DATE}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for symbol, info in tqdm(nifty_100_mapping.items(), desc=\"Collecting stock data\"):\n",
    "    isin = info['isin']\n",
    "    name = info['name']\n",
    "    \n",
    "    print(f\"\\n Processing: {symbol} ({name})\")\n",
    "    \n",
    "    # Fetch historical data\n",
    "    df = fetch_historical_data(\n",
    "        isin=isin,\n",
    "        interval='days',\n",
    "        candle_interval='1',\n",
    "        start_date=START_DATE,\n",
    "        end_date=END_DATE,\n",
    "        access_token=UPSTOX_ACCESS_TOKEN\n",
    "    )\n",
    "    \n",
    "    if df is not None and len(df) > 0:\n",
    "        print(f\"   Fetched {len(df)} records\")\n",
    "        \n",
    "        # Add technical indicators\n",
    "        df = add_technical_indicators(df)\n",
    "        print(f\"   Added technical indicators\")\n",
    "        \n",
    "        # Add metadata\n",
    "        df['Symbol'] = symbol\n",
    "        df['Name'] = name\n",
    "        df['ISIN'] = isin\n",
    "        \n",
    "        # Save to CSV\n",
    "        if save_stock_data(df, symbol, name):\n",
    "            print(f\"   Saved to {symbol}_historical.csv\")\n",
    "            collection_stats['successful'].append(symbol)\n",
    "            collection_stats['total_records'] += len(df)\n",
    "        else:\n",
    "            collection_stats['failed'].append(symbol)\n",
    "    else:\n",
    "        print(f\"   Failed to fetch data\")\n",
    "        collection_stats['failed'].append(symbol)\n",
    "    \n",
    "    # Rate limiting - be nice to the API\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA COLLECTION COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\" Successful: {len(collection_stats['successful'])} stocks\")\n",
    "print(f\" Failed: {len(collection_stats['failed'])} stocks\")\n",
    "print(f\" Total records collected: {collection_stats['total_records']:,}\")\n",
    "\n",
    "if collection_stats['failed']:\n",
    "    print(f\"\\n  Failed stocks:\")\n",
    "    for stock in collection_stats['failed']:\n",
    "        print(f\"   - {stock}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "es3gz3hgpn4",
   "metadata": {},
   "source": [
    "## 6. Data Inspection & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eez59z8j35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all collected stock data files\n",
    "import glob\n",
    "\n",
    "csv_files = glob.glob(os.path.join(STOCK_DATA_DIR, \"*_historical.csv\"))\n",
    "print(f\"Total CSV files: {len(csv_files)}\")\n",
    "print(f\"\\nSample files:\")\n",
    "for file in csv_files[:5]:\n",
    "    filename = os.path.basename(file)\n",
    "    filesize = os.path.getsize(file) / 1024  # KB\n",
    "    print(f\"  - {filename:<30} ({filesize:.2f} KB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yqmq48kcyfr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect a sample stock (e.g., RELIANCE)\n",
    "sample_symbol = 'RELIANCE'\n",
    "sample_df = load_stock_data(sample_symbol)\n",
    "\n",
    "if sample_df is not None:\n",
    "    print(f\"Stock: {sample_symbol}\")\n",
    "    print(f\"Shape: {sample_df.shape}\")\n",
    "    print(f\"Date range: {sample_df['Date'].min()} to {sample_df['Date'].max()}\")\n",
    "    print(f\"\\nColumns ({len(sample_df.columns)}):\")\n",
    "    print(sample_df.columns.tolist())\n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    display(sample_df.head())\n",
    "    print(f\"\\nBasic statistics:\")\n",
    "    display(sample_df[['Open', 'High', 'Low', 'Close', 'Volume']].describe())\n",
    "else:\n",
    "    print(f\" Could not load {sample_symbol}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g0ykf52t4ui",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample stock data\n",
    "if sample_df is not None:\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.05,\n",
    "        subplot_titles=(f'{sample_symbol} Price', 'Volume', 'RSI'),\n",
    "        row_heights=[0.5, 0.25, 0.25]\n",
    "    )\n",
    "    \n",
    "    # Candlestick chart\n",
    "    fig.add_trace(\n",
    "        go.Candlestick(\n",
    "            x=sample_df['Date'],\n",
    "            open=sample_df['Open'],\n",
    "            high=sample_df['High'],\n",
    "            low=sample_df['Low'],\n",
    "            close=sample_df['Close'],\n",
    "            name='Price'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Add moving averages\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=sample_df['Date'], y=sample_df['SMA_20'], \n",
    "                   name='SMA 20', line=dict(color='orange', width=1)),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=sample_df['Date'], y=sample_df['SMA_50'], \n",
    "                   name='SMA 50', line=dict(color='blue', width=1)),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Volume\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=sample_df['Date'], y=sample_df['Volume'], name='Volume', \n",
    "               marker_color='lightblue'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # RSI\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=sample_df['Date'], y=sample_df['RSI'], \n",
    "                   name='RSI', line=dict(color='purple', width=1)),\n",
    "        row=3, col=1\n",
    "    )\n",
    "    \n",
    "    # Add RSI levels\n",
    "    fig.add_hline(y=70, line_dash=\"dash\", line_color=\"red\", row=3, col=1)\n",
    "    fig.add_hline(y=30, line_dash=\"dash\", line_color=\"green\", row=3, col=1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        showlegend=True,\n",
    "        xaxis_rangeslider_visible=False,\n",
    "        title_text=f\"{sample_symbol} - Technical Analysis\"\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bto8c7a2g48",
   "metadata": {},
   "source": [
    "## 7. Create Combined Dataset for ML Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j8np2hcxxkl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all stock data into a single DataFrame (optional, for multi-stock analysis)\n",
    "def create_combined_dataset(limit: int = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Combine all stock data files into a single DataFrame\n",
    "    \n",
    "    Args:\n",
    "        limit: Limit number of stocks to load (None for all)\n",
    "    \n",
    "    Returns:\n",
    "        Combined DataFrame with all stocks\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    csv_files = glob.glob(os.path.join(STOCK_DATA_DIR, \"*_historical.csv\"))\n",
    "    \n",
    "    if limit:\n",
    "        csv_files = csv_files[:limit]\n",
    "    \n",
    "    print(f\"Loading {len(csv_files)} stock files...\")\n",
    "    \n",
    "    for file in tqdm(csv_files, desc=\"Loading files\"):\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            all_data.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file}: {e}\")\n",
    "    \n",
    "    if all_data:\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        print(f\"\\n Combined dataset shape: {combined_df.shape}\")\n",
    "        print(f\"   Date range: {combined_df['Date'].min()} to {combined_df['Date'].max()}\")\n",
    "        print(f\"   Unique stocks: {combined_df['Symbol'].nunique()}\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\" No data loaded\")\n",
    "        return None\n",
    "\n",
    "# Create combined dataset (load first 10 stocks as example)\n",
    "# combined_df = create_combined_dataset(limit=10)\n",
    "\n",
    "print(\" create_combined_dataset() function defined\")\n",
    "print(\"\\nTo create combined dataset, run:\")\n",
    "print(\"  combined_df = create_combined_dataset()  # All stocks\")\n",
    "print(\"  combined_df = create_combined_dataset(limit=10)  # First 10 stocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56z4qto53yh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save collection summary\n",
    "summary_data = {\n",
    "    'collection_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'date_range': {'start': START_DATE, 'end': END_DATE},\n",
    "    'total_stocks_attempted': len(nifty_100_mapping),\n",
    "    'successful_collections': len(collection_stats.get('successful', [])),\n",
    "    'failed_collections': len(collection_stats.get('failed', [])),\n",
    "    'total_records': collection_stats.get('total_records', 0),\n",
    "    'successful_stocks': collection_stats.get('successful', []),\n",
    "    'failed_stocks': collection_stats.get('failed', [])\n",
    "}\n",
    "\n",
    "summary_path = os.path.join(PROCESSED_DATA_DIR, 'collection_summary.json')\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary_data, f, indent=2)\n",
    "\n",
    "print(f\" Collection summary saved to: {summary_path}\")\n",
    "print(\"\\nSummary:\")\n",
    "print(json.dumps({k: v for k, v in summary_data.items() if k not in ['successful_stocks', 'failed_stocks']}, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock-curator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
