{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6889654",
   "metadata": {},
   "source": [
    "# Notebook 1: Data Ingestion & LLM Stock Extraction\n",
    "\n",
    "**Goal**: Validate the news scraping and LLM-based stock recommendation extraction pipeline\n",
    "\n",
    "**Workflow**:\n",
    "1. Scrape financial news from Indian websites\n",
    "2. Extract stock recommendations using Google Gemini API\n",
    "3. Validate stock symbols against NSE list\n",
    "4. Save results for next phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e1f14",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "081c4714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# LLM\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create necessary directories\n",
    "Path(\"data/raw/news\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"data/processed/recommendations\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7971f9df",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e13f5589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for date: 2025-10-06\n"
     ]
    }
   ],
   "source": [
    "# # API Configuration\n",
    "WORLD_NEWS_API_KEY = os.getenv(\"WORLD_NEWS_API_KEY\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# # Configure Gemini\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "\n",
    "# Date for this run\n",
    "TODAY = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "print(f\"Running for date: {TODAY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b409d96d",
   "metadata": {},
   "source": [
    "## 3. News Scraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e81f1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# worldnewsapi.com search-news API : https://worldnewsapi.com/docs/search-news/\n",
    "def world_news_api_function():\n",
    "    # Calculate the timestamp for 24 hours ago\n",
    "    published_after = (datetime.now() - timedelta(hours=24)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    params = {\n",
    "        'text': 'nifty OR stock OR share OR sensex OR market OR equity OR buy OR sell',\n",
    "        'source-country': 'in',\n",
    "        'language': 'en',\n",
    "        'earliest-publish-date': published_after,\n",
    "        'number': 20\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'x-api-key': WORLD_NEWS_API_KEY\n",
    "    }\n",
    "    \n",
    "    response = requests.get(\n",
    "        'https://api.worldnewsapi.com/search-news',\n",
    "        params=params,\n",
    "        headers=headers,\n",
    "        timeout=10\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f26eeb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get articles\n",
    "articles = world_news_api_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ce9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles.get('news')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "118e1bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/raw/news/worldnewsapi_2025-10-06.json\n"
     ]
    }
   ],
   "source": [
    "# refine the 'text' section of the articles\n",
    "# remove the text after 'Read more','About','Also Read',  if present\n",
    "for article in articles.get('news', []):\n",
    "    article['text'] = re.split(r'Read more|About|Also Read', article['text'], flags=re.IGNORECASE)[0].strip()\n",
    "\n",
    "# Save to json file\n",
    "TODAY = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "with open(f\"data/raw/news/worldnewsapi_{TODAY}.json\", \"w\") as f:\n",
    "    json.dump(articles, f, indent=4)\n",
    "\n",
    "print(f\"Data saved to data/raw/news/worldnewsapi_{TODAY}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc4466",
   "metadata": {},
   "source": [
    "## 4. LLM Stock Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9e11d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load filtered stock market listed equity data\n",
    "with open(\"data/processed/filtered_stock_data.json\", 'r') as f:\n",
    "    stocks_db = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83a0db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lookup_dict(stocks_db) -> Dict:\n",
    "    \"\"\"Create lookup dictionaries for efficient stock validation\"\"\"\n",
    "    lookup = {\n",
    "        'by_name': {},\n",
    "        'by_symbol': {},\n",
    "    }\n",
    "\n",
    "    for stock in stocks_db:\n",
    "        # Normalize names for matching\n",
    "        normalized_name = stock['name'].lower().strip()\n",
    "        lookup['by_name'][normalized_name] = stock\n",
    "        lookup['by_symbol'][stock['trading_symbol'].upper()] = stock\n",
    "        \n",
    "        # Add common variations\n",
    "        # Remove \"LIMITED\", \"LTD\", \"PVT\" etc.\n",
    "        short_name = normalized_name.replace(' limited', '').replace(' ltd', '')\n",
    "        short_name = short_name.replace(' pvt', '').strip()\n",
    "        lookup['by_name'][short_name] = stock\n",
    "        \n",
    "    return lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3b1515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_lookup = create_lookup_dict(stocks_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ffab5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the lookup dictionary for later use\n",
    "with open(\"data/processed/stock_lookup.json\", \"w\") as f:\n",
    "    json.dump(stock_lookup, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "684955a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extraction prompt for news articles\n",
    "\n",
    "def create_extraction_prompt(news_items: List[Dict]) -> str:\n",
    "    \"\"\"Create prompt for Gemini to extract stock recommendations\"\"\"\n",
    "    \n",
    "    # Prepare news text\n",
    "    news_text = \"\"\n",
    "    for idx, item in enumerate(news_items, 1):\n",
    "        news_text += f\"\\n\\n--- NEWS ID: {item['id']} ---\\n\"\n",
    "        news_text += f\"Title: {item['title']}\\n\"\n",
    "        news_text += f\"Text: {item['text']}\\n\"\n",
    "        news_text += f\"Summary: {item['summary']}\\n\"\n",
    "    \n",
    "    prompt = f\"\"\"You are a financial analyst expert in Indian stock markets (NSE/BSE).\n",
    "Extract stock information from financial news articles based on market-relevant events.\n",
    "\n",
    "{news_text}\n",
    "\n",
    "TASK:\n",
    "Extract stocks mentioned in these contexts:\n",
    "\n",
    "1. **EXPLICIT RECOMMENDATIONS**: Buy/Sell/Hold ratings with target prices\n",
    "2. **IPO ANNOUNCEMENTS**: Upcoming listings, IPO launches\n",
    "3. **EARNINGS/RESULTS**: Strong/weak quarterly results, earnings beats/misses\n",
    "4. **CORPORATE ACTIONS**: Stock splits, dividends, buybacks\n",
    "5. **CONTRACT WINS**: Major order announcements, government contracts\n",
    "6. **ANALYST COVERAGE**: Stocks added to watchlists, coverage initiations\n",
    "7. **SIGNIFICANT NEWS**: Strategic deals, expansions, regulatory approvals\n",
    "\n",
    "EXTRACTION RULES:\n",
    "- Extract ANY stock with market-relevant news (not just formal recommendations)\n",
    "- Use exact company names as mentioned\n",
    "- Infer sentiment from context (positive news → \"BUY_SIGNAL\", negative → \"SELL_SIGNAL\")\n",
    "- Set appropriate action_to_take based on news type\n",
    "- Extract IPOs even if just announced (set is_ipo=true, action=\"IPO_WATCH\")\n",
    "\n",
    "ACTION MAPPING:\n",
    "- Explicit \"Buy\" recommendation → \"BUY\"\n",
    "- Explicit \"Sell\" recommendation → \"SELL\"  \n",
    "- Explicit \"Hold\" recommendation → \"HOLD\"\n",
    "- Positive news (earnings beat, contract win, etc.) → \"BUY_SIGNAL\"\n",
    "- Negative news (earnings miss, loss, etc.) → \"SELL_SIGNAL\"\n",
    "- Neutral/watchlist mention → \"WATCH\"\n",
    "- IPO announcement → \"IPO_WATCH\"\n",
    "\n",
    "**DEDUPLICATION:**\n",
    "If same stock appears multiple times in one article:\n",
    "- Conflicting signals: Create separate entries\n",
    "- Similar signals: Merge with combined reasoning, average prices, lowest confidence\n",
    "\n",
    "OUTPUT FORMAT (JSON):\n",
    "[\n",
    "{{\n",
    "    \"news_id\": <news_id>,\n",
    "    \"stock_name\": \"<company name>\",\n",
    "    \"is_ipo\": true|false,\n",
    "    \"ipo_details\": {{\n",
    "        \"expected_listing_date\": \"<date or null>\",\n",
    "        \"price_range\": \"<range or null>\",\n",
    "        \"issue_size\": \"<size or null>\"\n",
    "    }} or null,\n",
    "    \"news_type\": \"recommendation|ipo|earnings|contract|corporate_action|analyst_coverage|strategic\",\n",
    "    \"reason_for_recommendation\": \"<specific catalyst/reason>\",\n",
    "    \"action_to_take\": \"BUY|SELL|HOLD|BUY_SIGNAL|SELL_SIGNAL|WATCH|IPO_WATCH|null\",\n",
    "    \"buy_price\": <float or null>,\n",
    "    \"target_price\": <float or null>,\n",
    "    \"target_price_range\": {{\"min\": <float>, \"max\": <float>}} or null,\n",
    "    \"timeframe\": \"<timeframe or null>\",\n",
    "    \"confidence\": <0.0 to 1.0>,\n",
    "    \"sentiment\": \"positive|negative|neutral\",\n",
    "    \"analyst_consensus\": \"unanimous|mixed|conflicting|null\"\n",
    "}}\n",
    "]\n",
    "\n",
    "EXAMPLES:\n",
    "\n",
    "Example 1 - Earnings Beat:\n",
    "\"Reliance Industries reported strong Q2 earnings with 25% YoY profit growth\"\n",
    "{{\n",
    "    \"stock_name\": \"Reliance Industries\",\n",
    "    \"is_ipo\": false,\n",
    "    \"news_type\": \"earnings\",\n",
    "    \"reason_for_recommendation\": \"Strong Q2 earnings with 25% YoY profit growth\",\n",
    "    \"action_to_take\": \"BUY_SIGNAL\",\n",
    "    \"sentiment\": \"positive\",\n",
    "    \"confidence\": 0.75\n",
    "}}\n",
    "\n",
    "Example 2 - Contract Win:\n",
    "\"L&T awarded Rs 5000 crore highway construction contract by government\"\n",
    "{{\n",
    "    \"stock_name\": \"L&T\",\n",
    "    \"is_ipo\": false,\n",
    "    \"news_type\": \"contract\",\n",
    "    \"reason_for_recommendation\": \"Awarded Rs 5000 crore government highway contract\",\n",
    "    \"action_to_take\": \"BUY_SIGNAL\",\n",
    "    \"sentiment\": \"positive\",\n",
    "    \"confidence\": 0.8\n",
    "}}\n",
    "\n",
    "Example 3 - Stock Split:\n",
    "\"Tata Motors announces 1:2 stock split to improve liquidity\"\n",
    "{{\n",
    "    \"stock_name\": \"Tata Motors\",\n",
    "    \"is_ipo\": false,\n",
    "    \"news_type\": \"corporate_action\",\n",
    "    \"reason_for_recommendation\": \"1:2 stock split announced to improve liquidity\",\n",
    "    \"action_to_take\": \"WATCH\",\n",
    "    \"sentiment\": \"neutral\",\n",
    "    \"confidence\": 0.65\n",
    "}}\n",
    "\n",
    "Example 4 - Watchlist:\n",
    "\"Add these 5 stocks to your radar: HDFC Bank, Infosys...\"\n",
    "{{\n",
    "    \"stock_name\": \"HDFC Bank\",\n",
    "    \"is_ipo\": false,\n",
    "    \"news_type\": \"analyst_coverage\",\n",
    "    \"reason_for_recommendation\": \"Added to analyst watchlist\",\n",
    "    \"action_to_take\": \"WATCH\",\n",
    "    \"sentiment\": \"positive\",\n",
    "    \"confidence\": 0.6\n",
    "}}\n",
    "\n",
    "Example 5 - IPO:\n",
    "\"Tata Capital's $1.7B IPO opens next week\"\n",
    "{{\n",
    "    \"stock_name\": \"Tata Capital Ltd.\",\n",
    "    \"is_ipo\": true,\n",
    "    \"ipo_details\": {{\"issue_size\": \"$1.7 billion\"}},\n",
    "    \"news_type\": \"ipo\",\n",
    "    \"reason_for_recommendation\": \"Upcoming $1.7B IPO from Tata Group\",\n",
    "    \"action_to_take\": \"IPO_WATCH\",\n",
    "    \"sentiment\": \"neutral\",\n",
    "    \"confidence\": 0.7\n",
    "}}\n",
    "\n",
    "Example 6 - Explicit Rating:\n",
    "\"Analysts recommend buying HDFC Bank with target ₹1800\"\n",
    "{{\n",
    "    \"stock_name\": \"HDFC Bank\",\n",
    "    \"is_ipo\": false,\n",
    "    \"news_type\": \"recommendation\",\n",
    "    \"reason_for_recommendation\": \"Analyst buy recommendation\",\n",
    "    \"action_to_take\": \"BUY\",\n",
    "    \"target_price\": 1800,\n",
    "    \"sentiment\": \"positive\",\n",
    "    \"confidence\": 0.9\n",
    "}}\n",
    "\n",
    "Example 7 - Negative News:\n",
    "\"Zomato reports quarterly loss, misses revenue estimates\"\n",
    "{{\n",
    "    \"stock_name\": \"Zomato\",\n",
    "    \"is_ipo\": false,\n",
    "    \"news_type\": \"earnings\",\n",
    "    \"reason_for_recommendation\": \"Quarterly loss, missed revenue estimates\",\n",
    "    \"action_to_take\": \"SELL_SIGNAL\",\n",
    "    \"sentiment\": \"negative\",\n",
    "    \"confidence\": 0.75\n",
    "}}\n",
    "\n",
    "If NO market-relevant stocks found:\n",
    "{{\n",
    "    \"news_id\": <news_id>,\n",
    "    \"stock_name\": null,\n",
    "    \"is_ipo\": null,\n",
    "    \"ipo_details\": null,\n",
    "    \"news_type\": null,\n",
    "    \"reason_for_recommendation\": null,\n",
    "    \"action_to_take\": null,\n",
    "    \"buy_price\": null,\n",
    "    \"target_price\": null,\n",
    "    \"target_price_range\": null,\n",
    "    \"timeframe\": null,\n",
    "    \"confidence\": 0.0,\n",
    "    \"sentiment\": null,\n",
    "    \"analyst_consensus\": null\n",
    "}}\n",
    "\n",
    "Return ONLY valid JSON, no additional text.\"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5282792e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20 news items...\n"
     ]
    }
   ],
   "source": [
    "# Load news data\n",
    "TODAY = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "news_file = f\"data/raw/news/worldnewsapi_{TODAY}.json\"\n",
    "\n",
    "with open(news_file, 'r') as f:\n",
    "    news_data = json.load(f)\n",
    "\n",
    "# Get news items\n",
    "news_items = news_data.get('news', [])\n",
    "\n",
    "print(f\"Processing {len(news_items)} news items...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a335abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = create_extraction_prompt(news_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11cf98a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the prompt to a text file for reference\n",
    "with open(f\"data/processed/recommendations/extraction_prompt_{TODAY}.txt\", \"w\") as f:\n",
    "    f.write(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0da1c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_recommendations(prompt):\n",
    "    \"\"\"Extract recommendations using Gemini\"\"\"\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        # Extract JSON from response\n",
    "        response_text = response.text.strip()\n",
    "        \n",
    "        # Remove markdown code blocks if present\n",
    "        if response_text.startswith('```'):\n",
    "            response_text = response_text.split('```')[1]\n",
    "            if response_text.startswith('json'):\n",
    "                response_text = response_text[4:]\n",
    "        \n",
    "        recommendations = json.loads(response_text.strip())\n",
    "        return recommendations\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing error: {e}\")\n",
    "        print(f\"Response: {response.text}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Gemini API: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "812dfec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759751640.918505  211628 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "LLM_recommendations = extract_recommendations(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ba7d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"LLM Recommendations: {LLM_recommendations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b0867a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save recommendations to json file\n",
    "with open(f\"data/processed/recommendations/llm_recommendations_{TODAY}.json\", \"w\") as f:\n",
    "    json.dump(LLM_recommendations, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f358c2a",
   "metadata": {},
   "source": [
    "## 5. Stock Symbol Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd80e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_enrich_stock(stock_name: str, is_ipo: bool = False) -> Tuple[Optional[Dict], Optional[str]]:\n",
    "    \"\"\"Validate stock name and return enriched data\"\"\"\n",
    "    if not stock_name:\n",
    "        return None, None\n",
    "    \n",
    "    if is_ipo:\n",
    "        # Create a placeholder stock entry for IPO\n",
    "        ipo_stock = {\n",
    "            'name': stock_name,\n",
    "            'trading_symbol': 'IPO_PENDING',\n",
    "            'instrument_key': None,\n",
    "            'isin': None,\n",
    "            'is_ipo': True\n",
    "        }\n",
    "        return ipo_stock, \"ipo_stock\"\n",
    "    \n",
    "    stock_name = stock_name.strip()\n",
    "    # print(f\"Validating stock: {stock_name}\")\n",
    "    \n",
    "    # Try exact symbol match first\n",
    "    if stock_name.upper() in stock_lookup['by_symbol']:\n",
    "        return stock_lookup['by_symbol'][stock_name.upper()], \"symbol match\"\n",
    "    \n",
    "    # Try exact name match\n",
    "    normalized = stock_name.lower()\n",
    "    if normalized in stock_lookup['by_name']:\n",
    "        return stock_lookup['by_name'][normalized], \"name match\"\n",
    "    \n",
    "    # Normalize the input for better matching\n",
    "    def normalize_for_matching(text):\n",
    "        \"\"\"Remove common suffixes and standardize text\"\"\"\n",
    "        text = text.lower()\n",
    "        # Remove common suffixes\n",
    "        text = re.sub(r'\\s+(ltd\\.?|limited|pvt\\.?|private|inc\\.?|incorporated|corp\\.?|corporation)$', '', text)\n",
    "        # Remove extra whitespace and special characters\n",
    "        text = re.sub(r'[&\\-\\.\\,]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    \n",
    "    def extract_key_words(text):\n",
    "        \"\"\"Extract significant words, handling abbreviations\"\"\"\n",
    "        text = normalize_for_matching(text)\n",
    "        words = text.split()\n",
    "        # Remove very common filler words\n",
    "        stop_words = {'and', 'the', 'of', 'a', 'an', 'in', 'on', 'at', 'to', 'for'}\n",
    "        return [w for w in words if w not in stop_words and len(w) > 1]\n",
    "    \n",
    "    def is_abbreviation_match(word, abbreviated):\n",
    "        \"\"\"Check if abbreviated form matches word (e.g., 'distillers' matches 'distils')\"\"\"\n",
    "        if word.startswith(abbreviated) or abbreviated.startswith(word):\n",
    "            return True\n",
    "        # Check if it could be an abbreviation (first few letters match)\n",
    "        if len(abbreviated) >= 4 and len(word) >= 4:\n",
    "            return abbreviated[:4] == word[:4]\n",
    "        return False\n",
    "    \n",
    "    def matches_acronym(acronym, full_name):\n",
    "        \"\"\"Check if acronym matches the first letters of words in full name\"\"\"\n",
    "        acronym = acronym.upper()\n",
    "        words = extract_key_words(full_name)\n",
    "        \n",
    "        if len(acronym) != len(words):\n",
    "            return False\n",
    "        \n",
    "        for i, word in enumerate(words):\n",
    "            if i >= len(acronym):\n",
    "                return False\n",
    "            if word[0].upper() != acronym[i]:\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    normalized_input = normalize_for_matching(stock_name)\n",
    "    input_words = extract_key_words(stock_name)\n",
    "    \n",
    "    # Special handling for bank stocks\n",
    "    bank_keywords = ['hdfc', 'icici', 'sbi', 'axis', 'kotak', 'bank']\n",
    "    is_bank_query = any(keyword in normalized_input for keyword in bank_keywords)\n",
    "    \n",
    "    if is_bank_query:\n",
    "        # For bank queries, we want to match actual banks, not ETFs or AMCs\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        \n",
    "        for key, stock in stock_lookup['by_name'].items():\n",
    "            key_lower = key.lower()\n",
    "            normalized_key = normalize_for_matching(key)\n",
    "            \n",
    "            # Skip ETFs and AMCs when looking for banks\n",
    "            if 'etf' in key_lower or 'amc' in key_lower or 'pramc' in key_lower:\n",
    "                continue\n",
    "            \n",
    "            # For insurance companies, only match if \"insurance\" or \"life\" is in the query\n",
    "            if 'insurance' in key_lower or 'life' in key_lower:\n",
    "                if 'insurance' not in normalized_input and 'life' not in normalized_input:\n",
    "                    continue\n",
    "            \n",
    "            # Must contain \"bank\" for bank queries (unless it's already in the input)\n",
    "            if 'bank' not in key_lower:\n",
    "                continue\n",
    "            \n",
    "            # Check short_name field if available\n",
    "            short_name_match = False\n",
    "            if 'short_name' in stock:\n",
    "                short_name_lower = stock['short_name'].lower()\n",
    "                if normalized_input == short_name_lower or stock_name.upper() == stock['short_name'].upper():\n",
    "                    return stock, \"short name match\"\n",
    "                if normalized_input in short_name_lower or short_name_lower in normalized_input:\n",
    "                    short_name_match = True\n",
    "            \n",
    "            # Check for acronym match (e.g., SBI -> State Bank India)\n",
    "            acronym_match = False\n",
    "            if len(stock_name) <= 5 and stock_name.isalpha() and stock_name.isupper():\n",
    "                if matches_acronym(stock_name, key):\n",
    "                    acronym_match = True\n",
    "            \n",
    "            key_words = extract_key_words(key)\n",
    "            \n",
    "            # Calculate match score\n",
    "            matches = 0\n",
    "            for input_word in input_words:\n",
    "                for key_word in key_words:\n",
    "                    if input_word == key_word or is_abbreviation_match(input_word, key_word):\n",
    "                        matches += 1\n",
    "                        break\n",
    "            \n",
    "            # For short queries like \"HDFC\", \"ICICI\", \"SBI\", be more lenient\n",
    "            if len(input_words) <= 2:\n",
    "                # Check if any input word is in the key\n",
    "                for input_word in input_words:\n",
    "                    if input_word in normalized_key:\n",
    "                        matches += 2  # Boost score for direct substring match\n",
    "            \n",
    "            score = matches / max(len(input_words), 1)\n",
    "            \n",
    "            # Boost for acronym match\n",
    "            if acronym_match:\n",
    "                score += 1.0\n",
    "            \n",
    "            # Boost for short name match\n",
    "            if short_name_match:\n",
    "                score += 0.8\n",
    "            \n",
    "            # Prioritize stocks with \"bank ltd\" or \"bank limited\" (actual banks)\n",
    "            if 'bank ltd' in key_lower or 'bank limited' in key_lower:\n",
    "                score += 0.5\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = stock\n",
    "        \n",
    "        if best_match and best_score > 0.5:\n",
    "            return best_match, \"bank priority match\"\n",
    "    \n",
    "    # General fuzzy matching for all stocks\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    \n",
    "    for key, stock in stock_lookup['by_name'].items():\n",
    "        normalized_key = normalize_for_matching(key)\n",
    "        key_words = extract_key_words(key)\n",
    "        \n",
    "        # Check short_name field if available\n",
    "        if 'short_name' in stock:\n",
    "            short_name_lower = stock['short_name'].lower()\n",
    "            if normalized_input == short_name_lower or stock_name.upper() == stock['short_name'].upper():\n",
    "                return stock, \"short name match\"\n",
    "        \n",
    "        # Calculate matching score based on word overlap with abbreviation support\n",
    "        matches = 0\n",
    "        for input_word in input_words:\n",
    "            for key_word in key_words:\n",
    "                if input_word == key_word or is_abbreviation_match(input_word, key_word):\n",
    "                    matches += 1\n",
    "                    break\n",
    "        \n",
    "        # Need at least half of the input words to match\n",
    "        if len(input_words) == 0:\n",
    "            continue\n",
    "            \n",
    "        score = matches / len(input_words)\n",
    "        \n",
    "        # Boost score if there's also a substring match\n",
    "        if normalized_input in normalized_key or normalized_key in normalized_input:\n",
    "            score += 0.3\n",
    "        \n",
    "        # Also check if most of the key words are matched (for abbreviated cases)\n",
    "        if len(key_words) > 0:\n",
    "            reverse_score = matches / len(key_words)\n",
    "            score = max(score, reverse_score)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = stock\n",
    "    \n",
    "    # Lower threshold for better recall\n",
    "    if best_match and best_score > 0.4:\n",
    "        return best_match, \"fuzzy match\"\n",
    "    \n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c81456a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_news(news_items: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Processes the news items and return validated recommendations\"\"\"\n",
    "    \n",
    "    # Create news lookup for quick access\n",
    "    news_lookup = {item['id']: item for item in news_items}\n",
    "\n",
    "    final_recommendations = []\n",
    "\n",
    "    # Validate and enrich recommendations\n",
    "    for rec in LLM_recommendations:\n",
    "        news_id = int(rec['news_id'])\n",
    "        news_item = news_lookup.get(news_id)\n",
    "\n",
    "        if not rec['stock_name']:\n",
    "            continue\n",
    "\n",
    "        # Validate stock\n",
    "        is_ipo = rec.get('is_ipo', False)\n",
    "        stock_data, method_used = validate_and_enrich_stock(rec.get('stock_name'), is_ipo=is_ipo)\n",
    "        \n",
    "        if stock_data:\n",
    "            # Build final recommendation object\n",
    "            recommendation = {\n",
    "                # News information\n",
    "                \"news_id\": news_id,\n",
    "                \"news_url\": news_item['url'],\n",
    "                \"publish_date\": news_item['publish_date'],\n",
    "                \n",
    "                # Equity information\n",
    "                \"equity_name\": stock_data['name'],\n",
    "                \"instrument_key\": stock_data['instrument_key'],\n",
    "                \"trading_symbol\": stock_data['trading_symbol'],\n",
    "                \"isin\": stock_data['isin'],\n",
    "                \n",
    "                # LLM extracted information\n",
    "                \"is_ipo\": is_ipo,\n",
    "                \"ipo_details\": rec.get('ipo_details') if is_ipo else None,\n",
    "                \"news_type\": rec.get('news_type'),\n",
    "                \"reason_for_recommendation\": rec.get('reason_for_recommendation'),\n",
    "                \"action_to_take\": rec.get('action_to_take'),\n",
    "                \"buy_price\": rec.get('buy_price'),\n",
    "                \"target_price\": rec.get('target_price'),\n",
    "                \"target_price_range\": rec.get('target_price_range'),\n",
    "                \"timeframe\": rec.get('timeframe'),\n",
    "                \"confidence\": rec.get('confidence', 0.0),\n",
    "                \"analyst_consensus\": rec.get('analyst_consensus'),\n",
    "                \n",
    "                # Metadata\n",
    "                \"extraction_timestamp\": datetime.now().isoformat(),\n",
    "                \"validated\": True,\n",
    "                'validation_method_used': method_used,\n",
    "            }\n",
    "        else:\n",
    "            # Stock not found in database\n",
    "            recommendation = {\n",
    "                \"news_id\": news_id,\n",
    "                \"news_url\": news_item['url'],\n",
    "                \"publish_date\": news_item['publish_date'],\n",
    "                \n",
    "                \"equity_name\": rec.get('stock_name'),\n",
    "                \"instrument_key\": None,\n",
    "                \"trading_symbol\": None,\n",
    "                \"isin\": None,\n",
    "                \n",
    "                \"is_ipo\": is_ipo,\n",
    "                \"ipo_details\": rec.get('ipo_details') if is_ipo else None,\n",
    "                \"news_type\": rec.get('news_type'),\n",
    "                \"reason_for_recommendation\": rec.get('reason_for_recommendation'),\n",
    "                \"action_to_take\": rec.get('action_to_take'),\n",
    "                \"buy_price\": rec.get('buy_price'),\n",
    "                \"target_price\": rec.get('target_price'),\n",
    "                \"target_price_range\": rec.get('target_price_range'), \n",
    "                \"timeframe\": rec.get('timeframe'),\n",
    "                \"confidence\": rec.get('confidence', 0.0),\n",
    "                \"analyst_consensus\": rec.get('analyst_consensus'), \n",
    "                \n",
    "                \"extraction_timestamp\": datetime.now().isoformat(),\n",
    "                \"validated\": False,\n",
    "                \"validation_error\": \"Stock not found in master database\"\n",
    "            }\n",
    "        \n",
    "        final_recommendations.append(recommendation)\n",
    "    \n",
    "    return final_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "988e6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recommendations = process_news(news_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca0eeda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"all_recommendations: {all_recommendations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db2779",
   "metadata": {},
   "source": [
    "## Save the Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c7370a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Total recommendations extracted: 102\n",
      "Validated recommendations: 101\n",
      "\n",
      "Saved to:\n",
      "  All: data/processed/recommendations/all_recommendations_2025-10-06.json\n",
      "  Validated: data/processed/recommendations/validated_recommendations_2025-10-06.json\n"
     ]
    }
   ],
   "source": [
    "# Filter only validated recommendations\n",
    "validated_recommendations = [rec for rec in all_recommendations if rec.get('validated')]\n",
    "\n",
    "# Save results\n",
    "output_dir = Path(\"data/processed/recommendations\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save all recommendations\n",
    "all_output_file = output_dir / f\"all_recommendations_{TODAY}.json\"\n",
    "with open(all_output_file, 'w') as f:\n",
    "    json.dump(all_recommendations, f, indent=2)\n",
    "\n",
    "# Save only validated recommendations\n",
    "validated_output_file = output_dir / f\"validated_recommendations_{TODAY}.json\"\n",
    "with open(validated_output_file, 'w') as f:\n",
    "    json.dump(validated_recommendations, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"Total recommendations extracted: {len(all_recommendations)}\")\n",
    "print(f\"Validated recommendations: {len(validated_recommendations)}\")\n",
    "print(f\"\\nSaved to:\")\n",
    "print(f\"  All: {all_output_file}\")\n",
    "print(f\"  Validated: {validated_output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eefbd7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample validated recommendations:\n",
      "\n",
      "- TATA CONSULTANCY SERV LT (TCS)\n",
      "  Action: WATCH\n",
      "  Reason: Scheduled to announce Q2 results on October 9...\n",
      "  Confidence: 0.6\n",
      "\n",
      "- TATA ELXSI LIMITED (TATAELXSI)\n",
      "  Action: WATCH\n",
      "  Reason: Scheduled to announce Q2 results on October 9...\n",
      "  Confidence: 0.6\n",
      "\n",
      "- Tata Capital (IPO_PENDING)\n",
      "  Action: IPO_WATCH\n",
      "  Reason: IPO slated to open next week...\n",
      "  Confidence: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Print sample recommendations\n",
    "if validated_recommendations:\n",
    "    print(\"\\nSample validated recommendations:\")\n",
    "    for rec in validated_recommendations[:3]:\n",
    "        print(f\"\\n- {rec['equity_name']} ({rec['trading_symbol']})\")\n",
    "        print(f\"  Action: {rec['action_to_take']}\")\n",
    "        print(f\"  Reason: {rec['reason_for_recommendation'][:100]}...\")\n",
    "        print(f\"  Confidence: {rec['confidence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc6021c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock-curator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
